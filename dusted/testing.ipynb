{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import segment\n",
    "def Kmeans():\n",
    "    model = KMeans(100)\n",
    "    checkpoint = torch.hub.load_state_dict_from_url(\n",
    "    \"https://github.com/bshall/dusted/releases/download/v0.1/kmeans-english-50f36a.pt\"\n",
    "    )\n",
    "    model.__dict__[\"n_features_in_\"] = checkpoint[\"n_features_in_\"]\n",
    "    model.__dict__[\"_n_threads\"] = checkpoint[\"_n_threads\"]\n",
    "    model.__dict__[\"cluster_centers_\"] = checkpoint[\"cluster_centers_\"].numpy()\n",
    "    return model, segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_file(paths, codebook, segment, gamma):\n",
    "    in_path, out_path = paths\n",
    "    sequence = np.load(in_path)\n",
    "    codes, boundaries = segment(sequence, codebook, gamma)\n",
    "    np.savez(out_path.with_suffix(\".npz\"), codes=codes, boundaries=boundaries)\n",
    "    return sequence.shape[0], np.mean(np.diff(boundaries))\n",
    "\n",
    "def segment_dataset(args):\n",
    "    kmeans, segment = Kmeans()\n",
    "    in_paths = list(args.in_dir.rglob(\"*.npy\"))\n",
    "    out_paths = [args.out_dir / path.relative_to(args.in_dir) for path in in_paths]\n",
    "\n",
    "    for path in out_paths:\n",
    "        path.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    results = []\n",
    "    for path in tqdm(zip(in_paths, out_paths), desc=\"Processing segments\"):\n",
    "        result = process_file(paths=path, codebook=kmeans.cluster_centers_, segment=segment.segment, gamma=1)\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "    frames, boundary_length = zip(*results)\n",
    "    print(f\"Segmented {sum(frames) * 0.02 / 60 / 60:.2f} hours of audio\")\n",
    "    print(f\"Average segment length: {np.mean(boundary_length) * 0.02:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing segments: 468it [00:35, 13.15it/s]\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "CPUDispatcher(<function _segment at 0x71e1952659e0>) returned a result with an exception set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/acoustic-unit-discovery/.env/lib/python3.12/site-packages/numba/core/serialize.py:30\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     27\u001b[0m _unpickled_memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        unpickled object\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <function _numba_unpickle at 0x71e19c045d00> returned a result with an exception set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dir \u001b[38;5;241m=\u001b[39m out_dir\n\u001b[1;32m      6\u001b[0m args \u001b[38;5;241m=\u001b[39m Args(Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures/\u001b[39m\u001b[38;5;124m\"\u001b[39m),Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodes/\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[43msegment_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 20\u001b[0m, in \u001b[0;36msegment_dataset\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     18\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(in_paths, out_paths), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing segments\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_centers_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     24\u001b[0m frames, boundary_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m, in \u001b[0;36mprocess_file\u001b[0;34m(paths, codebook, segment, gamma)\u001b[0m\n\u001b[1;32m      4\u001b[0m in_path, out_path \u001b[38;5;241m=\u001b[39m paths\n\u001b[1;32m      5\u001b[0m sequence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(in_path)\n\u001b[0;32m----> 6\u001b[0m codes, boundaries \u001b[38;5;241m=\u001b[39m \u001b[43msegment\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodebook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(out_path\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m), codes\u001b[38;5;241m=\u001b[39mcodes, boundaries\u001b[38;5;241m=\u001b[39mboundaries)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mdiff(boundaries))\n",
      "File \u001b[0;32m~/Documents/acoustic-unit-discovery/dusted/segment.py:7\u001b[0m, in \u001b[0;36msegment\u001b[0;34m(sequence, codebook, gamma)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msegment\u001b[39m(sequence, codebook, gamma):\n\u001b[1;32m      6\u001b[0m     dists \u001b[38;5;241m=\u001b[39m distance\u001b[38;5;241m.\u001b[39mcdist(sequence, codebook)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 7\u001b[0m     alpha, P \u001b[38;5;241m=\u001b[39m \u001b[43m_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _backtrack(alpha, P)\n",
      "\u001b[0;31mSystemError\u001b[0m: CPUDispatcher(<function _segment at 0x71e1952659e0>) returned a result with an exception set"
     ]
    }
   ],
   "source": [
    "\n",
    "class Args:\n",
    "    def __init__(self, in_dir, out_dir):\n",
    "        self.in_dir =in_dir\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "args = Args(Path(\"features/\"),Path(\"codes/\"))\n",
    "\n",
    "segment_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bounds = [0, 14, 25, 30, 35, 36]\n",
    "boundaries = [0, 13, 25, 27, 29, 30, 31, 32, 36]\n",
    "encodings = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "features = []\n",
    "prev_j = 1\n",
    "for i in range(1, len(true_bounds)):\n",
    "    new_feature = []\n",
    "    for j in range(prev_j, len(boundaries)):\n",
    "        if true_bounds[i] < boundaries[j]:\n",
    "            continue\n",
    "\n",
    "        if true_bounds[i] == boundaries[j]:\n",
    "            new_feature.append(encodings[j-1])\n",
    "            \n",
    "        elif true_bounds[i] > boundaries[j]:\n",
    "            new_feature.append(encodings[j-1])\n",
    "        \n",
    "        prev_j = j + 1\n",
    "        \n",
    "    features.append(new_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg size cluster for file output/librispeech_subset/wavlm_base/8/0.05/norm_distance_matrix.npy: 1.9774436090225564\n",
      "Avg size cluster for file output/librispeech_subset/wavlm_base/8/0.1/norm_distance_matrix.npy: 2.8452380952380953\n",
      "Avg size cluster for file output/librispeech_subset/wavlm_base/8/0.15/norm_distance_matrix.npy: 4.326923076923077\n",
      "Avg size cluster for file output/librispeech_subset/wavlm_base/8/0.2/norm_distance_matrix.npy: 5.666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "in_dir = Path(\"output/librispeech_subset/\")\n",
    "\n",
    "for path in list(in_dir.rglob(\"*.npy\")):\n",
    "    mat = np.load(path)\n",
    "\n",
    "    DISTANCE_THRESHOLD = round(np.mean(mat)/3,3)\n",
    "    num_nodes = mat.shape[0]\n",
    "    graph = {i: set() for i in range(num_nodes)}\n",
    "\n",
    "    for i in range(num_nodes - 1): \n",
    "        for j in range(i + 1, num_nodes):  \n",
    "            if mat[i, j] < DISTANCE_THRESHOLD:\n",
    "                graph[i].add(j)\n",
    "                graph[j].add(i)  \n",
    "\n",
    "\n",
    "    clusters = []\n",
    "    visited = set()\n",
    "\n",
    "    def bfs(start_node):\n",
    "        \"\"\" Traverse a cluster using BFS \"\"\"\n",
    "        queue = [start_node]\n",
    "        cluster = []\n",
    "        \n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            if node in visited:\n",
    "                continue\n",
    "            visited.add(node)\n",
    "            cluster.append(node)\n",
    "            queue.extend(graph[node])  \n",
    "\n",
    "        return cluster\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if node not in visited:\n",
    "            new_cluster = bfs(node)\n",
    "            clusters.append(new_cluster)\n",
    "\n",
    "    sizes = []\n",
    "    for i, clust in enumerate(clusters):\n",
    "        sizes.append(len(clust))\n",
    "\n",
    "    print(f\"Avg size cluster for file {str(path)}: {np.mean(sizes)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The whole dusted pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding into HuBERT or WAVLM features\n",
    "import  torchaudio\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model_pipelines = {\n",
    "    \"hubert_base\": torchaudio.pipelines.HUBERT_BASE,\n",
    "    \"hubert_large\": torchaudio.pipelines.HUBERT_LARGE,\n",
    "    \"hubert_xlarge\": torchaudio.pipelines.HUBERT_XLARGE,\n",
    "    \"wavlm_base\": torchaudio.pipelines.WAVLM_BASE,\n",
    "    \"wavlm_large\": torchaudio.pipelines.WAVLM_LARGE,\n",
    "    \"wavlm_base_plus\": torchaudio.pipelines.WAVLM_BASE_PLUS,\n",
    "}\n",
    "\n",
    "def encode_features(args):\n",
    "    wavs = list(args.in_dir.rglob(f\"*{args.audio_ext}\"))\n",
    "\n",
    "    bundle = model_pipelines.get(args.model, torchaudio.pipelines.HUBERT_BASE)\n",
    "    model = bundle.get_model().cuda()\n",
    "    model.eval()\n",
    "\n",
    "    out_dir = None\n",
    "    if args.out_dir:\n",
    "        out_dir = args.out_dir / args.model / str(args.layer)\n",
    "        print(f\"Storing Encodings in {str(out_dir)}\")\n",
    "\n",
    "    encodings = {}\n",
    "    for wav_path in tqdm(wavs, desc=\"Encoding Audio Features\"):\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000).cuda()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            encoding, _ = model.extract_features(wav, num_layers=args.layer)\n",
    "\n",
    "        encoding = encoding[args.layer-1].squeeze().cpu().numpy()\n",
    "        \n",
    "        if out_dir:\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            output_path = Path(out_dir) / f\"{wav_path.stem}.npy\"\n",
    "            np.save(output_path, encoding)\n",
    "            \n",
    "        else:\n",
    "            encodings[wav_path.stem] = encoding\n",
    "    return encodings         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Audio Features: 100%|██████████| 14/14 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(\n",
    "    in_dir=Path(\"data/librispeech_subset/\"),\n",
    "    out_dir=None,\n",
    "    model=\"wavlm_base\",\n",
    "    layer=6,\n",
    "    audio_ext=\".wav\"\n",
    ")\n",
    "\n",
    "encodings = encode_features(args)\n",
    "print(len(encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "in_dir = Path(\"data/librispeech-wav\")\n",
    "sample_size = 15\n",
    "\n",
    "wav_paths = list(in_dir.rglob(\"*.wav\"))\n",
    "sampled_paths = random.sample(wav_paths, sample_size)  \n",
    "\n",
    "print(sampled_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the dataset into discrete acoustic units\n",
    "from sklearn.cluster import KMeans\n",
    "import segment\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_model(url):\n",
    "    model = KMeans(100)\n",
    "    checkpoint = torch.hub.load_state_dict_from_url(url)\n",
    "\n",
    "    model.__dict__[\"n_features_in_\"] = checkpoint[\"n_features_in_\"]\n",
    "    model.__dict__[\"_n_threads\"] = checkpoint[\"_n_threads\"]\n",
    "    model.__dict__[\"cluster_centers_\"] = checkpoint[\"cluster_centers_\"].numpy()\n",
    "    return model, segment\n",
    "\n",
    "def apply_kmeans(kmeans_model, encoding):\n",
    "    # C = cluster centers matrix\n",
    "    C_np = kmeans_model.cluster_centers_.transpose()\n",
    "    Cnorm_np = (C_np ** 2).sum(0, keepdims=True)\n",
    "\n",
    "    C = torch.from_numpy(C_np)\n",
    "    Cnorm = torch.from_numpy(Cnorm_np)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        C = C.cuda()\n",
    "        Cnorm = Cnorm.cuda()\n",
    "    \n",
    "    if isinstance(encoding, torch.Tensor):\n",
    "        dist = (\n",
    "            encoding.pow(2).sum(1, keepdims=True)-2*torch.matmul(encoding, C)+Cnorm\n",
    "        )\n",
    "    else:\n",
    "        dist = (\n",
    "            (encoding**2).sum(1, keepdims=True)-2*np.matmul(encoding, C_np)+Cnorm_np\n",
    "        )\n",
    "    return np.argmin(dist, axis=1)\n",
    "\n",
    "def get_frame_num(timestamp: float, sample_rate: int, frame_size_ms: int)->int:\n",
    "    \"\"\"\n",
    "    Convert timestamp (in seconds) to frame index based on sampling rate and frame size.\n",
    "    \"\"\"\n",
    "    hop_size = frame_size_ms/1000 * sample_rate\n",
    "    hop_size = np.max([hop_size, 1])\n",
    "    return int((timestamp * sample_rate) / hop_size)\n",
    "\n",
    "\n",
    "def segment_dataset_kmeans(args):\n",
    "    kmeans, _ = kmeans_model(args.kmeans_url)\n",
    "    encodings = []\n",
    "\n",
    "    if args.in_dir:\n",
    "        in_dir = args.in_dir / args.model \n",
    "        in_paths = list(in_dir.rglob(\"*.npy\"))\n",
    "        encodings = {}\n",
    "        for path in tqdm(in_paths, desc=\"Loading Features\"):\n",
    "            encoding = np.load(path)\n",
    "            encodings[path.stem] = encoding\n",
    "\n",
    "    elif args.encodings:\n",
    "        encodings = args.encodings\n",
    "\n",
    "    if args.out_dir:\n",
    "        out_dir = args.out_dir / args.model / str(args.layer)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    align_paths = list(args.align_dir.rglob(\"*.list\"))\n",
    "    \n",
    "    codes_dict = {}\n",
    "\n",
    "    for path in tqdm(encodings, desc=\"Extracting Kmeans codes\"):\n",
    "        alignment_file = [a for a in align_paths if a.stem == path]\n",
    "        if not alignment_file:\n",
    "            continue\n",
    "        else:\n",
    "            alignment_file = alignment_file[0]\n",
    "\n",
    "        with open(str(alignment_file), \"r\") as f:\n",
    "            bounds = [get_frame_num(float(line.strip()), 16000, 20) for line in f]\n",
    "        \n",
    "        words = []\n",
    "        for i in range(len(bounds)-1):\n",
    "            cut_encoding = encodings[path][bounds[i]: bounds[i+1]]\n",
    "            codes = apply_kmeans(kmeans, cut_encoding).tolist()\n",
    "            words.append(codes)\n",
    "        codes_dict[path] = words\n",
    "        \n",
    "    return codes_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the dataset into discrete acoustic units using DUSTED\n",
    "from sklearn.cluster import KMeans\n",
    "from segment import segment\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_model(url):\n",
    "    model = KMeans(100)\n",
    "    checkpoint = torch.hub.load_state_dict_from_url(url)\n",
    "\n",
    "    model.__dict__[\"n_features_in_\"] = checkpoint[\"n_features_in_\"]\n",
    "    model.__dict__[\"_n_threads\"] = checkpoint[\"_n_threads\"]\n",
    "    model.__dict__[\"cluster_centers_\"] = checkpoint[\"cluster_centers_\"].numpy()\n",
    "    return model, segment\n",
    "\n",
    "def get_frame_num(timestamp: float, sample_rate: int, frame_size_ms: int)->int:\n",
    "    \"\"\"\n",
    "    Convert timestamp (in seconds) to frame index based on sampling rate and frame size.\n",
    "    \"\"\"\n",
    "    hop_size = frame_size_ms/1000 * sample_rate\n",
    "    hop_size = np.max([hop_size, 1])\n",
    "    return int((timestamp * sample_rate) / hop_size)\n",
    "\n",
    "def segment_dataset_dusted(args):\n",
    "    kmeans, segment = kmeans_model(args.kmeans_url)\n",
    "    encodings = []\n",
    "    align_paths = list(args.align_dir.rglob(\"*.list\"))\n",
    "\n",
    "    if args.in_dir:\n",
    "        in_dir = args.in_dir / args.model \n",
    "        in_paths = list(in_dir.rglob(\"*.npy\"))\n",
    "        encodings = {}\n",
    "        for path in tqdm(in_paths, desc=\"Loading Features\"):\n",
    "            encoding = np.load(path)\n",
    "            encodings[path.stem] = encoding\n",
    "\n",
    "    elif args.encodings:\n",
    "        encodings = args.encodings\n",
    "\n",
    "    if args.out_dir:\n",
    "        out_dir = args.out_dir / args.model / str(args.layer)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    codes_dict = {}\n",
    "    for path in tqdm(encodings, desc=\"Extracting DUSTED codes\"):\n",
    "        alignment_file = [a for a in align_paths if a.stem == path]\n",
    "        if not alignment_file:\n",
    "            continue\n",
    "        else:\n",
    "            alignment_file = alignment_file[0]\n",
    "\n",
    "        with open(str(alignment_file), \"r\") as f:\n",
    "            bounds = [get_frame_num(float(line.strip()), 16000, 20) for line in f]\n",
    "        \n",
    "        words = []\n",
    "        for i in range(len(bounds)-1):\n",
    "            cut_encoding = encodings[path][bounds[i]: bounds[i+1]]\n",
    "            codes, _ = segment(cut_encoding, kmeans.cluster_centers_, args.gamma)   \n",
    "            words.append(codes)\n",
    "        codes_dict[path] = words\n",
    "        \n",
    "    return codes_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DUSTED codes: 100%|██████████| 14/14 [00:00<00:00, 124.29it/s]\n",
      "Extracting DUSTED codes: 100%|██████████| 14/14 [00:00<00:00, 164.22it/s]\n"
     ]
    }
   ],
   "source": [
    "args = Args(\n",
    "    in_dir=None,\n",
    "    out_dir=None,\n",
    "    align_dir=Path(\"data/all_alignments/\"),\n",
    "    model=\"wavlm_base\",\n",
    "    layer=6,\n",
    "    audio_ext=\".wav\",\n",
    "    kmeans_url=\"https://github.com/bshall/dusted/releases/download/v0.1/kmeans-english-50f36a.pt\",\n",
    "    gamma=0.02,\n",
    "    encodings=encodings\n",
    ")\n",
    "\n",
    "dusted_codes_dict = segment_dataset_dusted(args)\n",
    "codes_dict = segment_dataset_kmeans(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251-118436-0003\n",
      "[97 24 18 70]\n",
      "[18, 97, 24, 24, 24, 24, 24, 18, 18, 18, 70, 70, 70]\n",
      "\n",
      "[70 95 97]\n",
      "[70, 95, 95, 97, 97, 97, 97]\n",
      "\n",
      "[24 70 95 97 95 18]\n",
      "[24, 24, 97, 70, 95, 95, 95, 97, 95, 95, 18, 18, 18]\n",
      "\n",
      "[70 18 28 40 18]\n",
      "[70, 70, 70, 18, 28, 40, 40, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      "[97 70 18 97]\n",
      "[97, 24, 97, 70, 18, 18, 18, 18, 18, 97]\n",
      "\n",
      "[18]\n",
      "[18, 18, 18, 18, 18]\n",
      "\n",
      "[18 70 18 97 95]\n",
      "[18, 18, 18, 97, 18, 70, 70, 18, 18, 97, 97, 97, 97, 95, 18, 95, 95, 95, 97, 95]\n",
      "\n",
      "[97 24 97 18 95 70 97 18]\n",
      "[97, 95, 97, 97, 24, 24, 24, 97, 40, 97, 18, 95, 95, 95, 95, 95, 70, 70, 70, 97, 18]\n",
      "\n",
      "[18 24 18 95]\n",
      "[18, 24, 24, 18, 18, 18, 18, 95, 95]\n",
      "\n",
      "[95 70 18 97 18]\n",
      "[95, 97, 70, 70, 70, 18, 18, 97, 97, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      "[18 95 97 95 18 95 18]\n",
      "[18, 97, 95, 95, 40, 0, 18, 97, 95, 95, 95, 95, 18, 95, 95, 18, 18, 18, 40, 18, 18]\n",
      "\n",
      "[18 95 18 24 97]\n",
      "[18, 18, 18, 95, 95, 95, 18, 18, 2, 18, 24, 97]\n",
      "\n",
      "[24 70 97 18]\n",
      "[24, 70, 70, 70, 97, 97, 97, 18, 18, 18, 18, 18]\n",
      "\n",
      "[97 18 95]\n",
      "[97, 97, 97, 97, 97, 97, 97, 40, 18, 18, 18, 18, 18, 95, 95, 95]\n",
      "\n",
      "[95 18 95 18 97 95 18 97 95]\n",
      "[95, 95, 97, 18, 18, 18, 18, 95, 95, 18, 18, 97, 97, 97, 97, 97, 95, 95, 95, 18, 18, 18, 97, 95, 95, 95]\n",
      "\n",
      "[40 18]\n",
      "[40, 18, 95, 18, 18]\n",
      "\n",
      "[18]\n",
      "[18, 18, 95, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      "[18]\n",
      "[18, 18]\n",
      "\n",
      "[18 70 97 18 97 95 18 95]\n",
      "[18, 18, 70, 70, 70, 97, 18, 18, 18, 18, 18, 97, 95, 18, 18, 18, 18, 95]\n",
      "\n",
      "[95 18]\n",
      "[95, 95, 95, 95, 18, 95, 95, 18, 18]\n",
      "\n",
      "[95 18 95 97 95 18]\n",
      "[95, 95, 43, 95, 95, 97, 18, 18, 95, 95, 95, 95, 97, 97, 97, 95, 18]\n",
      "\n",
      "[18 95 18]\n",
      "[18, 18, 18, 18, 18, 95, 95, 18]\n",
      "\n",
      "[70 24 97 95 18 95 18]\n",
      "[70, 24, 24, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 18, 95, 95, 95, 95, 95, 95, 95, 18, 95, 95, 18, 18]\n",
      "\n",
      "[97 18 97 95  2 97]\n",
      "[97, 18, 24, 18, 18, 18, 97, 95, 2, 2, 97]\n",
      "\n",
      "[18 95 97 24 97 95]\n",
      "[18, 18, 95, 97, 24, 24, 24, 97, 95, 18, 95, 95]\n",
      "\n",
      "[95 97 18 95 18 97 24 18]\n",
      "[95, 95, 95, 95, 97, 2, 97, 97, 97, 24, 18, 18, 18, 95, 95, 18, 18, 18, 18, 97, 97, 24, 18, 18, 18]\n",
      "\n",
      "[18 97 18 97 18]\n",
      "[18, 18, 18, 18, 97, 97, 97, 97, 95, 95, 97, 18, 97, 97, 18, 97, 18, 18]\n",
      "\n",
      "[18 97 18 95 18]\n",
      "[18, 18, 18, 18, 18, 24, 97, 95, 97, 97, 97, 97, 97, 18, 18, 18, 95, 95, 95, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      "[97 53 95 97 18]\n",
      "[97, 97, 97, 53, 53, 53, 95, 95, 97, 97, 97, 97, 97, 97, 18, 97]\n",
      "\n",
      "[95 18]\n",
      "[95, 95, 95, 95, 95, 95, 95, 18, 18]\n",
      "\n",
      "[18 95 18 95 53 18 97 24]\n",
      "[18, 18, 18, 18, 53, 53, 53, 18, 18, 95, 95, 95, 95, 18, 18, 18, 95, 95, 53, 18, 18, 18, 18, 18, 18, 18, 18, 97, 24, 18]\n",
      "\n",
      "[18 24 18 95 18 24]\n",
      "[18, 18, 24, 24, 40, 18, 95, 95, 18, 24]\n",
      "\n",
      "[24 97 70 18]\n",
      "[24, 97, 97, 70, 70, 18, 18, 18]\n",
      "\n",
      "[18 53 18 97 95]\n",
      "[18, 95, 18, 18, 53, 53, 18, 97, 97, 97, 97, 97, 18, 97, 97, 95, 95]\n",
      "\n",
      "[18 95]\n",
      "[18, 18, 18, 95, 95, 95, 18]\n",
      "\n",
      "[18 24 97 18 95]\n",
      "[18, 18, 18, 24, 24, 24, 24, 97, 97, 97, 97, 18, 18, 95, 95, 95, 95, 95, 95, 95, 97, 95, 95, 95]\n",
      "\n",
      "[18 97 18 95 18]\n",
      "[18, 97, 97, 18, 18, 95, 95, 95, 18, 18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in dusted_codes_dict:\n",
    "    print(path)\n",
    "    \n",
    "    for word in range(len(dusted_codes_dict[path])):\n",
    "        print(dusted_codes_dict[path][word])\n",
    "        print(codes_dict[path][word])\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting DUSTED codes: 100%|██████████| 14/14 [00:00<00:00, 125.04it/s]\n"
     ]
    }
   ],
   "source": [
    "args = Args(\n",
    "    in_dir=None,\n",
    "    out_dir=None,\n",
    "    model=\"wavlm_base\",\n",
    "    align_dir=Path(\"data/all_alignments\"),\n",
    "    layer=6,\n",
    "    audio_ext=\".wav\",\n",
    "    kmeans_url=\"https://github.com/bshall/dusted/releases/download/v0.1/kmeans-english-50f36a.pt\",\n",
    "    gamma=0.2,\n",
    "    encodings=encodings\n",
    ")\n",
    "\n",
    "codes_dict = segment_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cutting into words: 100%|██████████| 14/14 [00:00<00:00, 1114.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Getting the word codes\n",
    "\n",
    "def get_frame_num(timestamp: float, sample_rate: int, frame_size_ms: int)->int:\n",
    "    \"\"\"\n",
    "    Convert timestamp (in seconds) to frame index based on sampling rate and frame size.\n",
    "    \"\"\"\n",
    "    hop_size = frame_size_ms/1000 * sample_rate\n",
    "    hop_size = np.max([hop_size, 1])\n",
    "    return int((timestamp * sample_rate) / hop_size)\n",
    "\n",
    "def word_codes(align_paths, codes_dict):\n",
    "    words_dict = {}\n",
    "    word_count = 0\n",
    "    for path in tqdm(codes_dict, desc=\"Cutting into words\"):\n",
    "        alignment_file = [a for a in align_paths if a.stem == path]\n",
    "        \n",
    "        if alignment_file:\n",
    "            alignment_file = alignment_file[0]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        with open(str(alignment_file), \"r\") as f:\n",
    "            bounds = [get_frame_num(float(line.strip()), 16000, 20) for line in f]\n",
    "        boundaries = []\n",
    "        boundaries.extend(bounds)\n",
    "\n",
    "        feature_codes = []\n",
    "        codes = codes_dict[path]\n",
    "        for i in range(len(boundaries)-1):\n",
    "            new_codes = codes[boundaries[i]:boundaries[i+1]]\n",
    "            feature_codes.append(new_codes)\n",
    "            word_count += 1\n",
    "        words_dict[path] = feature_codes\n",
    "    return words_dict, word_count\n",
    "\n",
    "align_dir = Path(\"data/all_alignments\")\n",
    "align_paths = list(align_dir.rglob(\"*.list\"))\n",
    "words_dict, num_words = word_codes(align_paths, codes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "dict_ind = {}\n",
    "\n",
    "just_words_dusted = []\n",
    "just_word_kmeans = []\n",
    "\n",
    "index = 0\n",
    "for path in dusted_codes_dict:\n",
    "    dict_ind[path] = []\n",
    "    for i in range(len(dusted_codes_dict[path])):\n",
    "        just_words_dusted.append(dusted_codes_dict[path][i])\n",
    "        dict_ind[path].append(index)\n",
    "        index += 1\n",
    "\n",
    "    for j in range(len(codes_dict[path])):\n",
    "        just_word_kmeans.append(codes_dict[path][j])\n",
    "    \n",
    "    \n",
    "collapsed_kmeans = []\n",
    "for path in codes_dict:\n",
    "    for j in range(len(codes_dict[path])):\n",
    "        collapsed_word = [key for key, _ in groupby(codes_dict[path][j])]\n",
    "        collapsed_kmeans.append(collapsed_word)\n",
    "        # print(f\"{codes_dict[path][j]} --> {collapsed_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Distances: 100%|██████████| 140/140 [00:04<00:00, 29.05it/s]\n",
      "Calculating Distances: 100%|██████████| 140/140 [00:05<00:00, 26.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def edit_distance(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Compute the edit distance between two sequences using dynamic programming.\n",
    "    \"\"\"\n",
    "    N, M = len(seq1), len(seq2)\n",
    "    dp = np.zeros((N + 1, M + 1))\n",
    "    for i in range(N + 1):\n",
    "        dp[i, 0] = i\n",
    "    for j in range(M + 1):\n",
    "        dp[0, j] = j\n",
    "    for i in range(1, N + 1):\n",
    "        for j in range(1, M + 1):\n",
    "            cost = 0 if seq1[i - 1] == seq2[j - 1] else 1\n",
    "            dp[i, j] = min(dp[i - 1, j] + 1, dp[i, j - 1] + 1, dp[i - 1, j - 1] + cost)\n",
    "    return dp[N, M] \n",
    "\n",
    "def calculate_distance(just_words, num_words):\n",
    "    num_words = int(num_words/2)\n",
    "    dist_mat = np.zeros((num_words, num_words))\n",
    "\n",
    "    for i in tqdm(range(num_words), desc=\"Calculating Distances\"):\n",
    "        js = [j for j in range(i + 1, num_words)]\n",
    "        dists_i = Parallel(n_jobs=8)(\n",
    "            delayed(edit_distance)(just_words[i], just_words[j]) for j in js\n",
    "        )\n",
    "\n",
    "        for j, dist in zip(js, dists_i):\n",
    "            dist_mat[i, j] = dist\n",
    "            dist_mat[j, i] = dist  \n",
    "    \n",
    "    return dist_mat\n",
    "\n",
    "dist_mat_kmeans = calculate_distance(just_word_kmeans, num_words)\n",
    "dist_mat_dusted = calculate_distance(just_words_dusted, num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 4. 5. 5. 2. 3. 4. 4. 2. 4. 5. 4. 4. 2. 7. 3. 3. 3. 6. 3.]\n",
      " [4. 0. 3. 4. 2. 3. 3. 6. 4. 3. 5. 3. 3. 3. 7. 3. 3. 3. 6. 2.]\n",
      " [5. 3. 0. 4. 4. 5. 3. 5. 5. 3. 4. 5. 2. 5. 5. 5. 5. 5. 4. 4.]\n",
      " [5. 4. 4. 0. 4. 4. 4. 6. 4. 3. 6. 5. 4. 4. 7. 3. 4. 4. 5. 4.]\n",
      " [2. 2. 4. 4. 0. 3. 2. 5. 3. 2. 5. 3. 3. 2. 6. 3. 3. 3. 5. 3.]]\n",
      "\n",
      "[[ 0. 13. 12. 12.  8.  9. 16. 13.  7. 11. 16. 10. 10. 12. 21. 11.  9. 11.\n",
      "  14. 11.]\n",
      " [13.  0.  9. 15.  8.  7. 15. 16.  9. 12. 18.  9.  8. 12. 20.  6.  8.  7.\n",
      "  15.  7.]\n",
      " [12.  9.  0. 13.  8. 10. 15. 13. 10. 10. 12.  9.  7. 12. 17. 10.  9. 11.\n",
      "  12.  6.]\n",
      " [12. 15. 13.  0. 11. 11. 16. 18. 11.  7. 14. 12.  9. 11. 20. 12.  8. 14.\n",
      "   9. 13.]\n",
      " [ 8.  8.  8. 11.  0.  5. 14. 16.  5.  8. 14.  8.  7.  9. 19.  7.  5.  8.\n",
      "  11.  7.]]\n"
     ]
    }
   ],
   "source": [
    "print(dist_mat_dusted[0:5, 0:20])\n",
    "print()\n",
    "print(dist_mat_kmeans[0:5, 0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"output/wavlm_base_6.npy\", dist_mat)\n",
    "def cluster(dist_mat, distance_threshold):\n",
    "    num_nodes = dist_mat.shape[0]\n",
    "    graph = {i: set() for i in range(num_nodes)}\n",
    "\n",
    "    for i in range(num_nodes - 1): \n",
    "        for j in range(i + 1, num_nodes):  \n",
    "            if dist_mat[i, j] < distance_threshold:\n",
    "                graph[i].add(j)\n",
    "                graph[j].add(i)  \n",
    "\n",
    "\n",
    "    clusters = []\n",
    "    visited = set()\n",
    "\n",
    "    def bfs(start_node):\n",
    "        \"\"\" Traverse a cluster using BFS \"\"\"\n",
    "        queue = [start_node]\n",
    "        cluster = []\n",
    "        \n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            if node in visited:\n",
    "                continue\n",
    "            visited.add(node)\n",
    "            cluster.append(node)\n",
    "            queue.extend(graph[node])  \n",
    "\n",
    "        return cluster\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if node not in visited:\n",
    "            new_cluster = bfs(node)\n",
    "            clusters.append(new_cluster)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "116\n",
      "Cluster 5: [5, 99, 16, 17, 50, 86]\n",
      "Cluster 13: [13, 60, 55]\n",
      "Cluster 17: [19, 81, 90, 29]\n",
      "Cluster 19: [21, 112]\n",
      "Cluster 25: [27, 36]\n",
      "Cluster 31: [34, 64, 71]\n",
      "Cluster 34: [38, 72, 42]\n",
      "Cluster 47: [53, 57, 124]\n",
      "Cluster 57: [67, 108]\n",
      "Cluster 68: [80, 119]\n",
      "Cluster 75: [89, 104, 110, 135]\n",
      "\n",
      "Cluster 5: [5, 138, 110, 15, 115, 86, 34, 104, 118, 67, 99, 17, 50, 21, 135, 89, 71, 94]\n",
      "Cluster 8: [8, 54]\n",
      "Cluster 17: [19, 29]\n",
      "Cluster 33: [38, 90]\n",
      "Cluster 37: [42, 72]\n",
      "Cluster 47: [53, 103, 120]\n",
      "Cluster 96: [114, 134]\n"
     ]
    }
   ],
   "source": [
    "dusted_clusters = cluster(dist_mat_dusted, 1)\n",
    "kmeans_clusters = cluster(dist_mat_kmeans, 2.5)\n",
    "\n",
    "print(len(dusted_clusters))\n",
    "print(len(kmeans_clusters))\n",
    "\n",
    "for i, c in enumerate(dusted_clusters):\n",
    "    if(len(c)>1):\n",
    "        print(f\"Cluster {i}: {c}\")\n",
    "\n",
    "print()\n",
    "for i, c in enumerate(kmeans_clusters):\n",
    "    if(len(c)>1):\n",
    "        print(f\"Cluster {i}: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_to_dict(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data_dict = {}\n",
    "    current_id = None\n",
    "    word_dict = {}\n",
    "\n",
    "    for line in lines: \n",
    "        line = line.strip()\n",
    "\n",
    "        if not line: \n",
    "            continue\n",
    "        \n",
    "        if line.endswith(\":\") and not line.split(\":\")[0].isdigit():\n",
    "            if current_id is not None:\n",
    "                data_dict[current_id] = word_dict\n",
    "            \n",
    "            current_id = line[:-1]\n",
    "            word_dict = {}\n",
    "        else:\n",
    "            parts = line.split(\": \")\n",
    "            if len(parts) == 2:\n",
    "                index, word = parts\n",
    "                word_dict[int(index)] = word.strip()\n",
    "            else:\n",
    "                parts = parts[0].split(\":\")\n",
    "                index = parts[0]\n",
    "                word_dict[int(index)] = \" \"\n",
    "            \n",
    "            if current_id is not None:\n",
    "                data_dict[current_id] = word_dict\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "true_words_dict = parse_text_to_dict(\"data/words_and_indices.txt\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'as', 1: 'you', 2: 'well', 3: 'know', 4: 'there', 5: 'are', 6: 'ten', 7: 'men', 8: 'and', 9: 'ten', 10: 'women', 11: ' ', 12: 'whose', 13: 'sole', 14: 'duty', 15: 'is', 16: 'to', 17: ' ', 18: 'taste', 19: 'his', 20: 'food', 21: 'and', 22: 'wine', 23: ' ', 24: 'and', 25: 'fifty', 26: 'armed', 27: 'warriors', 28: 'guard', 29: 'his', 30: 'chamber', 31: 'as', 32: 'they', 33: 'guard', 34: 'it', 35: 'now', 36: ' ', 37: 'since', 38: 'his', 39: 'birth', 40: ' ', 41: 'he', 42: 'has', 43: 'been', 44: 'guarded', 45: 'so', 46: 'closely', 47: ' ', 48: 'that', 49: 'the', 50: ' ', 51: 'cleverest', 52: 'poisoners', 53: 'of', 54: 'the', 55: 'east', 56: 'could', 57: 'not', 58: 'reach', 59: 'him', 60: ' ', 61: 'the', 62: \"emperor's\", 63: 'daughter', 64: ' ', 65: 'a', 66: 'low', 67: ' ', 68: 'confused', 69: 'moan', 70: 'waned', 71: 'from', 72: 'his', 73: 'mouth', 74: ' ', 75: 'he', 76: 'was', 77: 'young', 78: ' ', 79: 'no', 80: 'spear', 81: 'had', 82: 'touched', 83: 'him', 84: ' ', 85: 'no', 86: ' ', 87: 'poison', 88: 'lurked', 89: 'in', 90: 'his', 91: 'wine', 92: ' ', 93: 'worse', 94: 'and', 95: 'worse', 96: ' ', 97: 'he', 98: 'is', 99: ' ', 100: 'even', 101: 'presumed', 102: 'to', 103: 'be', 104: 'the', 105: \"captive's\", 106: 'sweetheart', 107: ' ', 108: 'who', 109: 'wheedles', 110: 'the', 111: 'flower', 112: 'the', 113: 'ring', 114: 'and', 115: 'the', 116: 'prison', 117: 'key', 118: 'out', 119: 'of', 120: 'the', 121: 'strict', 122: 'virgins', 123: 'for', 124: 'his', 125: 'own', 126: 'purposes', 127: ' ', 128: 'and', 129: 'flies', 130: 'with', 131: 'her', 132: 'at', 133: 'last', 134: 'in', 135: 'his', 136: 'shallop', 137: 'across', 138: 'the', 139: 'sea', 140: ' ', 141: 'to', 142: 'live', 143: 'with', 144: 'her', 145: 'happily', 146: 'ever', 147: 'after', 148: ' ', 149: 'i', 150: 'tell', 151: 'you', 152: ' ', 153: 'it', 154: 'is', 155: 'not', 156: 'poison', 157: ' ', 158: 'she', 159: 'cried', 160: ' ', 161: 'forgotten', 162: 'too', 163: ' ', 164: 'the', 165: 'name', 166: 'of', 167: 'gillian', 168: ' ', 169: 'the', 170: 'lovely', 171: 'captive', 172: ' ', 173: 'but', 174: 'in', 175: 'less', 176: 'than', 177: 'five', 178: 'minutes', 179: 'the', 180: 'staircase', 181: 'groaned', 182: 'beneath', 183: 'an', 184: 'extraordinary', 185: 'weight', 186: ' ', 187: 'go', 188: ' ', 189: 'do', 190: 'you', 191: 'hear', 192: ' ', 193: 'the', 194: 'wandering', 195: 'singer', 196: 'approaches', 197: 'them', 198: 'with', 199: 'his', 200: 'lute', 201: ' ', 202: 'lady', 203: ' ', 204: 'lady', 205: ' ', 206: 'my', 207: 'rose', 208: 'white', 209: 'lady', 210: ' ', 211: 'but', 212: 'will', 213: 'you', 214: 'not', 215: 'hear', 216: 'a', 217: 'roundel', 218: 'lady', 219: ' ', 220: 'at', 221: 'this', 222: 'moment', 223: ' ', 224: 'the', 225: 'whole', 226: 'soul', 227: 'of', 228: 'the', 229: 'old', 230: 'man', 231: 'seemed', 232: 'centred', 233: 'in', 234: 'his', 235: 'eyes', 236: 'which', 237: 'became', 238: 'bloodshot', 239: ' ', 240: 'the', 241: 'veins', 242: 'of', 243: 'the', 244: 'throat', 245: 'swelled', 246: ' ', 247: 'his', 248: 'cheeks', 249: 'and', 250: 'temples', 251: 'became', 252: 'purple', 253: 'as', 254: 'though', 255: 'he', 256: 'was', 257: 'struck', 258: 'with', 259: 'epilepsy', 260: ' ', 261: 'nothing', 262: 'was', 263: 'wanting', 264: 'to', 265: 'complete', 266: 'this', 267: 'but', 268: 'the', 269: 'utterance', 270: 'of', 271: 'a', 272: 'cry', 273: ' ', 274: 'but', 275: 'this', 276: 'is', 277: 'a', 278: 'fallacy', 279: ' '}\n"
     ]
    }
   ],
   "source": [
    "path_dict = {}\n",
    "for path in dict_ind:\n",
    "    for i in range(len(dict_ind[path])):\n",
    "        path_dict[dict_ind[path][i]] = true_words_dict[path][i]\n",
    "    \n",
    "print(path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dusted clusters\n",
      "Cluster 5: are,  , to,  ,  ,  \n",
      "Cluster 13: sole,  , east\n",
      "Cluster 17: his, had, his, his\n",
      "Cluster 19: and, the\n",
      "Cluster 25: warriors,  \n",
      "Cluster 31: it,  , from\n",
      "Cluster 34: his, his, has\n",
      "Cluster 47: of, not, his\n",
      "Cluster 57:  , who\n",
      "Cluster 68: spear, of\n",
      "Cluster 75: in, the, the, his\n",
      "\n",
      "Kmeans clusters\n",
      "Cluster 5: are, the, the, is, the,  , it, the, out,  ,  ,  ,  , and, his, in, from, and\n",
      "Cluster 8: and, the\n",
      "Cluster 17: his, his\n",
      "Cluster 33: his, his\n",
      "Cluster 37: has, his\n",
      "Cluster 47: of, be, the\n",
      "Cluster 96: and, in\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Dusted clusters\")\n",
    "for i, c in enumerate(dusted_clusters):\n",
    "    if(len(c)>1):\n",
    "        words = [path_dict[c[j]] for j in range(len(c))]\n",
    "        print(f\"Cluster {i}: {', '.join(words)}\")\n",
    "\n",
    "print(\"\\nKmeans clusters\")\n",
    "for i, c in enumerate(kmeans_clusters):\n",
    "    if(len(c)>1):\n",
    "        words = [path_dict[c[j]] for j in range(len(c))]\n",
    "        print(f\"Cluster {i}: {', '.join(words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
