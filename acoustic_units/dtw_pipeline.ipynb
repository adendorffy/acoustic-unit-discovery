{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model_name = \"wavlm_base\"\n",
    "layer = 8\n",
    "in_dir = Path(\"data/librispeech-wav\")\n",
    "sample_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample files to read\n",
    "import random\n",
    "\n",
    "wav_paths = list(in_dir.rglob(\"*.wav\"))\n",
    "sampled_paths = random.sample(wav_paths, sample_size)  \n",
    "\n",
    "print(len(sampled_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Audio Features: 100%|██████████| 200/200 [00:07<00:00, 26.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored Encodings in features/wavlm_base/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode the sampled audio features \n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def preemphasis(signal, coeff=0.97):\n",
    "    return np.append(signal[0], signal[1:] - coeff*signal[:-1])\n",
    "\n",
    "model_pipelines = {\n",
    "    \"hubert_base\": torchaudio.pipelines.HUBERT_BASE,\n",
    "    \"hubert_large\": torchaudio.pipelines.HUBERT_LARGE,\n",
    "    \"hubert_xlarge\": torchaudio.pipelines.HUBERT_XLARGE,\n",
    "    \"wavlm_base\": torchaudio.pipelines.WAVLM_BASE,\n",
    "    \"wavlm_large\": torchaudio.pipelines.WAVLM_LARGE,\n",
    "    \"wavlm_base_plus\": torchaudio.pipelines.WAVLM_BASE_PLUS,\n",
    "}\n",
    "\n",
    "if model_name != \"mfcc\":\n",
    "    bundle = model_pipelines.get(model_name, torchaudio.pipelines.HUBERT_BASE)\n",
    "    model = bundle.get_model().cuda()\n",
    "    model.eval()\n",
    "\n",
    "encodings = {}\n",
    "for wav_path in tqdm(sampled_paths, desc=\"Encoding Audio Features\"):\n",
    "    if model_name != \"mfcc\":\n",
    "        out_dir = Path(\"features/\") / model_name / str(layer)\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000).cuda()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            encoding, _ = model.extract_features(wav, num_layers=layer)\n",
    "\n",
    "        encoding = encoding[layer-1].squeeze().cpu().numpy()\n",
    "    else:\n",
    "        out_dir = Path(\"features/\") / model_name \n",
    "        wav, sr = librosa.core.load(wav_path, sr=None)\n",
    "        wav = preemphasis(wav, coeff=0.97)\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=wav, sr=sr, n_mfcc=13, n_mels=24, \n",
    "            n_fft=int(np.floor(0.025*sr)),\n",
    "            hop_length=int(np.floor(0.01*sr)), \n",
    "            fmin=64, fmax=8000\n",
    "        )\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta_delta = librosa.feature.delta(mfcc_delta)\n",
    "        encoding = np.hstack([mfcc.T, mfcc_delta.T, mfcc_delta_delta.T])\n",
    "\n",
    "    if out_dir:\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_path = Path(out_dir) / f\"{wav_path.stem}.npy\"\n",
    "        np.save(output_path, encoding)\n",
    "    encodings[wav_path.stem] = encoding\n",
    "print(f\"Stored Encodings in {str(out_dir)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cutting Encodings:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cutting Encodings: 100%|██████████| 200/200 [00:00<00:00, 921.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cut encodings\n",
    "def get_frame_num(timestamp: float, sample_rate: int, frame_size_ms: int)->int:\n",
    "    hop_size = frame_size_ms/1000 * sample_rate\n",
    "    hop_size = np.max([hop_size, 1])\n",
    "    return int((timestamp * sample_rate) / hop_size)\n",
    "\n",
    "out_dir = Path(\"output/codes/kmeans\")\n",
    "align_dir = Path(\"data/all_alignments\")\n",
    "\n",
    "if out_dir and model_name != \"mfcc\":\n",
    "    out_dir = out_dir / model_name / str(layer)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    out_dir = out_dir / model_name \n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "align_paths = list(align_dir.rglob(\"*.list\"))\n",
    "\n",
    "cut_encodings = {}\n",
    "filenames = {}\n",
    "features = []\n",
    "index = 0\n",
    "for path in tqdm(encodings, desc=\"Cutting Encodings\"):\n",
    "    alignment_file = [a for a in align_paths if a.stem == path]\n",
    "    if not alignment_file:\n",
    "        continue\n",
    "    else:\n",
    "        alignment_file = alignment_file[0]\n",
    "\n",
    "    with open(str(alignment_file), \"r\") as f:\n",
    "        bounds = [get_frame_num(float(line.strip()), 16000, 20) for line in f]\n",
    "    \n",
    "    cut_encoding = encodings[path][0: bounds[0]]\n",
    "    words = [cut_encoding]\n",
    "    for i in range(len(bounds)-1): \n",
    "        cut_encoding = encodings[path][bounds[i]: bounds[i+1]]\n",
    "        features.append(cut_encoding)\n",
    "        words.append(cut_encoding)\n",
    "        filenames[index] = f\"{path}_{i}\"\n",
    "        index += 1\n",
    "    cut_encodings[path] = words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dictionaries to arrays and getting the index for each of the words in the dataset\n",
    "dict_ind = {}\n",
    "\n",
    "index = 0\n",
    "for path in cut_encodings:\n",
    "    dict_ind[path] = []\n",
    "    for i in range(len(cut_encodings[path])):\n",
    "        \n",
    "        dict_ind[path].append(index)\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def dtw_sweep_min(query_seq, search_seq, n_step=3):\n",
    "    \"\"\"\n",
    "    Return the minimum DTW cost as `query_seq` is swept across `search_seq`.\n",
    "\n",
    "    Step size can be specified with `n_step`.\n",
    "    \"\"\"\n",
    "\n",
    "    from cython_dtw import _dtw\n",
    "    dtw_cost_func = _dtw.multivariate_dtw_cost_cosine\n",
    "\n",
    "    i_start = 0\n",
    "    n_query = query_seq.shape[0]\n",
    "    n_search = search_seq.shape[0]\n",
    "    min_cost = np.inf\n",
    "\n",
    "    while i_start <= n_search - n_query or i_start == 0:\n",
    "        cost = dtw_cost_func(\n",
    "            query_seq, search_seq[i_start:i_start + n_query], True\n",
    "        )\n",
    "        i_start += n_step\n",
    "        if cost < min_cost:\n",
    "            min_cost = cost\n",
    "\n",
    "    return min_cost\n",
    "\n",
    "def dtw(features):\n",
    "    tensor_features = [torch.from_numpy(f) for f in features]\n",
    "    stacked_features = torch.cat(tensor_features, dim=0)\n",
    "    normalized_features = []\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(stacked_features) \n",
    "    normalized_features = []\n",
    "    for feature in tqdm(features, desc=\"Normalizing Features\"):\n",
    "        normalized_features.append(torch.from_numpy(scaler.transform(feature))) \n",
    "    \n",
    "    num_features = len(normalized_features)\n",
    "    norm_distance_mat = np.zeros((num_features, num_features))\n",
    "    normalized_features = [f.cpu().numpy().astype(np.float64) for f in normalized_features]\n",
    "\n",
    "    for i in tqdm(range(num_features), desc=\"Calculating Distances\"):\n",
    "        dists_i = Parallel(n_jobs=8)(\n",
    "            delayed(dtw_sweep_min)(normalized_features[i], normalized_features[j])\n",
    "            for j in range(i + 1, num_features)\n",
    "        )\n",
    "\n",
    "        for j, dist in zip(range(i + 1, num_features), dists_i):\n",
    "            norm_distance_mat[i, j] = dist\n",
    "            norm_distance_mat[j, i] = dist  \n",
    "            \n",
    "    return norm_distance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing Features: 100%|██████████| 4519/4519 [00:00<00:00, 7574.07it/s]\n",
      "Calculating Distances:   2%|▏         | 88/4519 [00:47<39:43,  1.86it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mascontiguousarray(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m----> 2\u001b[0m dist_mat_dtw \u001b[38;5;241m=\u001b[39m \u001b[43mdtw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m, in \u001b[0;36mdtw\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     43\u001b[0m normalized_features \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m normalized_features]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_features), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating Distances\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     dists_i \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtw_sweep_min\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, dist \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_features), dists_i):\n\u001b[1;32m     52\u001b[0m         norm_distance_mat[i, j] \u001b[38;5;241m=\u001b[39m dist\n",
      "File \u001b[0;32m~/Documents/acoustic-unit-discovery/.env/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/acoustic-unit-discovery/.env/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/acoustic-unit-discovery/.env/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = [np.ascontiguousarray(f) for f in features]\n",
    "dist_mat_dtw = dtw(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(f\"output/mat/{model_name}/{layer}/{sample_size}\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(out_dir/\"dist_mat_dtw.npy\", dist_mat_dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.77427764 0.62808591 0.82940389 0.60451699 0.51741716\n",
      "  0.65911661 0.57893458 0.63977625 0.52445605 0.86401942 0.53740024\n",
      "  0.53804338 0.51582226 0.79152627]\n",
      " [0.77427764 0.         0.47698115 0.4889294  0.45792736 0.48271909\n",
      "  0.48642485 0.47579694 0.46931661 0.46506085 0.53923493 0.49407092\n",
      "  0.48735931 0.48461273 0.47290599]\n",
      " [0.62808591 0.47698115 0.         0.71116497 0.4877622  0.46296147\n",
      "  0.52707392 0.49795275 0.51340117 0.485275   0.79112062 0.45228296\n",
      "  0.49596127 0.42601075 0.67789985]\n",
      " [0.82940389 0.4889294  0.71116497 0.         0.46298309 0.49831581\n",
      "  0.50299457 0.51038167 0.46485221 0.47627475 0.55977701 0.48228696\n",
      "  0.48960585 0.45335487 0.47485141]\n",
      " [0.60451699 0.45792736 0.4877622  0.46298309 0.         0.40703904\n",
      "  0.58386042 0.44892431 0.50620716 0.49410235 0.7856648  0.49195152\n",
      "  0.46742061 0.46823171 0.69137271]]\n",
      "(2150, 2150)\n"
     ]
    }
   ],
   "source": [
    "print(dist_mat_dtw[0:5, 0:15])\n",
    "print(dist_mat_dtw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering algorithm \n",
    "\n",
    "def cluster(dist_mat, distance_threshold):\n",
    "    num_nodes = dist_mat.shape[0]\n",
    "    graph = {i: set() for i in range(num_nodes)}\n",
    "\n",
    "    for i in range(num_nodes - 1): \n",
    "        for j in range(i + 1, num_nodes):  \n",
    "            if dist_mat[i, j] < distance_threshold:\n",
    "                graph[i].add(j)\n",
    "                graph[j].add(i)  \n",
    "\n",
    "\n",
    "    clusters = []\n",
    "    visited = set()\n",
    "\n",
    "    def bfs(start_node):\n",
    "        \"\"\" Traverse a cluster using BFS \"\"\"\n",
    "        queue = [start_node]\n",
    "        cluster = []\n",
    "        \n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            if node in visited:\n",
    "                continue \n",
    "            visited.add(node)\n",
    "            cluster.append(node)\n",
    "            queue.extend(graph[node])  \n",
    "\n",
    "        return cluster\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if node not in visited:\n",
    "            new_cluster = bfs(node)\n",
    "            clusters.append(new_cluster)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  3.  4.  4.  4.  6.  4.  4.  6.  6.]\n",
      " [ 3.  0.  7.  3.  5.  8.  4.  3.  8.  7.]\n",
      " [ 4.  7.  0.  4.  4.  7.  4.  5.  6.  5.]\n",
      " [ 4.  3.  4.  0.  3.  9.  4.  4.  9.  6.]\n",
      " [ 4.  5.  4.  3.  0.  9.  5.  5.  9.  9.]\n",
      " [ 6.  8.  7.  9.  9.  0.  0.  3.  6.  4.]\n",
      " [ 4.  4.  4.  4.  5.  0.  0.  4. 10.  7.]\n",
      " [ 4.  3.  5.  4.  5.  3.  4.  0.  8.  7.]\n",
      " [ 6.  8.  6.  9.  9.  6. 10.  8.  0.  2.]\n",
      " [ 6.  7.  5.  6.  9.  4.  7.  7.  2.  0.]]\n",
      "{1, 2, 3, 4, 6, 7}\n",
      "{0, 3, 6, 7}\n",
      "{0, 3, 4, 6}\n",
      "{0, 1, 2, 4, 6, 7}\n",
      "{0, 2, 3}\n",
      "{9, 6, 7}\n",
      "{0, 1, 2, 3, 5, 7}\n",
      "{0, 1, 3, 5, 6}\n",
      "{9}\n"
     ]
    }
   ],
   "source": [
    "# Evaluating clustering on dist_mat_dtw\n",
    "dist_mat_dtw_round = np.round(dist_mat_dtw[0:10, 0:10]*10)\n",
    "print(dist_mat_dtw_round)\n",
    "\n",
    "distance_thresh = 5\n",
    "\n",
    "num_nodes = dist_mat_dtw_round.shape[0]\n",
    "graph = {i: set() for i in range(num_nodes)}\n",
    "\n",
    "for i in range(num_nodes - 1): \n",
    "    for j in range(i + 1, num_nodes):  \n",
    "        if dist_mat_dtw_round[i, j] < distance_thresh:\n",
    "            graph[i].add(j)\n",
    "            graph[j].add(i)  \n",
    "\n",
    "for i in range(num_nodes-1):\n",
    "    print(graph[i])\n",
    "\n",
    "\n",
    "clusters = []\n",
    "visited = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True words Dictionary\n",
    "\n",
    "def parse_text_to_dict(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data_dict = {}\n",
    "    current_id = None\n",
    "    word_dict = {}\n",
    "\n",
    "    for line in lines: \n",
    "        line = line.strip()\n",
    "\n",
    "        if not line: \n",
    "            continue\n",
    "        \n",
    "        if line.endswith(\":\") and not line.split(\":\")[0].isdigit():\n",
    "            if current_id is not None:\n",
    "                data_dict[current_id] = word_dict\n",
    "            \n",
    "            current_id = line[:-1]\n",
    "            word_dict = {}\n",
    "        else:\n",
    "            parts = line.split(\": \")\n",
    "            if len(parts) == 2:\n",
    "                index, word = parts\n",
    "                word_dict[int(index)] = word.strip()\n",
    "            else:\n",
    "                parts = parts[0].split(\":\")\n",
    "                index = parts[0]\n",
    "                word_dict[int(index)] = \" \"\n",
    "            \n",
    "            if current_id is not None:\n",
    "                data_dict[current_id] = word_dict\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "true_words_dict = parse_text_to_dict(\"data/words_and_indices.txt\")\n",
    "\n",
    "path_dict = {}\n",
    "for path in dict_ind:\n",
    "    path_dict[dict_ind[path][0]] = ''\n",
    "    for i in range(1, len(dict_ind[path])):\n",
    "        path_dict[dict_ind[path][i]] = true_words_dict[path][i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster and WordUnit classes\n",
    "from collections import defaultdict\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self,id, word_dict=None, true_words=None):\n",
    "        self.id = id\n",
    "        self.length = len(word_dict) if word_dict else 0\n",
    "        self.word_dict = word_dict if word_dict is not None else []\n",
    "        self.true_word_dict = true_words if true_words is not None else []\n",
    "    \n",
    "    def add_word_unit(self, id, index, file):\n",
    "        word_unit = WordUnit(file, index, id)\n",
    "        self.length += 1\n",
    "        self.word_dict.append(word_unit)\n",
    "\n",
    "    def add_true_word(self, word):\n",
    "        self.true_word_dict.append(word)\n",
    "\n",
    "    @classmethod\n",
    "    def print_cluster(self, cluster):\n",
    "        print(f\"Cluster {cluster.id}\")\n",
    "        for word in cluster.word_dict:\n",
    "            print(f\"Word {word.id}: Index {word.index} in File {word.file}\")\n",
    "    \n",
    "    def cluster_purity(self):\n",
    "\n",
    "        word_counts = {}\n",
    "        for word in self.true_word_dict:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "        max_count = max(word_counts.values()) if word_counts else 0\n",
    "        cluster_purity = max_count / self.length if self.length > 0 else 0\n",
    "\n",
    "        self.purity = cluster_purity\n",
    "\n",
    "    @classmethod\n",
    "    def duplicate_clusters(self, clusters):\n",
    "        cluster_dict = defaultdict(int)\n",
    "\n",
    "        for cluster in clusters:\n",
    "            cluster_set = frozenset(cluster)  \n",
    "            cluster_dict[cluster_set] += 1  \n",
    "\n",
    "        duplicate_count = sum(1 for count in cluster_dict.values() if count > 1)\n",
    "\n",
    "        return duplicate_count\n",
    "\n",
    "class WordUnit:\n",
    "    def __init__(self, file, index, id):\n",
    "        self.index = int(index)\n",
    "        self.file = file\n",
    "        self.id = int(id)\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "\n",
    "    def add_word_boundaries(self, start_time, end_time):\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "['delighted']\n",
      "\n",
      "Cluster 1\n",
      "['to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', ' ', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'honest', 'no', 'does', 'portugal', 'pleasing', 'is', 'two', 'into', ' ', 'on', 'no', 'no', 'no', 'as', 'is', 'as', 'two', 'too', 'two', 'too', 'two', 'into', 'into', 'into', 'into', 'into', ' ', ' ', 'was', 'an', 'girls', 'kent', ' ', ' ', 'as', ' ', 'is', 'night', ' ', 'as', ' ', 'is', 'liquid', ' ', 'and', ' ', 'dinners', ' ', 'as', 'at', 'and', 'at', 'night', 'guard', 'wines', 'in', ' ', 'of', ' ', 'agreeable', 'on', 'on', 'know', 'is', 'as', 'is', 'is', 'is', 'is', 'is', 'is', 'as', 'two', 'into', 'into', 'into', 'into', ' ', ' ', ' ', 'was', 'was', 'was', ' ', 'was', 'was', 'were', 'was', ' ', 'an', 'as', 'as', 'as', 'as', 'introduced', 'events', 'error', 'without', 'any', 'until', 'after', 'herbs', 'seasoning', 'herb', 'night', 'in', 'and', ' ', 'and', ' ', 'and', 'any', 'as', 'as', 'at', 'and', 'and', 'and', 'and', 'and', 'night', 'guard', 'wines', 'and', 'and', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', ' ', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'a', 'a', 'a', 'a', 'in', 'as', 'recognized', ' ', 'he', ' ', ' ', ' ', ' ', ' ', 'until', 'due', 'character', ' ', 'man', 'best', ' ', 'he', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'was', 'eldest', 'ill', 'illinois', 'order', 'ultimately', 'organs', 'all', 'saint', 'animals', 'early', 'without', 'alternately', 'under', 'offer', 'avarice', 'several', 'orthodox', 'how', 'all', 'was', 'was', 'were', 'were', 'were', 'were', 'were', 'many', 'or', ' ', '<unk>', 'upon', 'in', ' ', 'as', 'as', 'with', 'with', 'any', 'any', 'after', 'see', 'see', 'in', 'in', 'in', 'in', 'and', 'and', 'and', 'and', 'and', ' ', ' ', ' ', ' ', ' ', 'and', 'and', 'and', 'at', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'in', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'have', 'of', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'thread', 'a', 'another', 'a', 'a', 'alarm', 'fulfill', 'in', 'in', 'in', 'in', 'in', 'recognise', ' ', 'man', ' ', 'man', 'battle', 'was', 'was', ' ', 'was', 'was', ' ', 'all', 'all', 'all', ' ', 'all', 'all', 'all', 'all', 'early', 'with', 'under', 'how', 'how', 'how', 'how', 'all', 'was', 'were', 'or', 'or', 'and', ' ', 'upon', 'and', 'tinkled', ' ', 'answer', ' ', ' ', 'as', 'with', 'with', 'with', 'with', 'with', 'with', 'see', 'see', 'saw', 'see', 'see', 'within', 'in', 'in', 'an', 'in', 'in', 'an', 'and', 'and', 'and', 'and', 'and', 'voyage', 'bartley', ' ', 'being', ' ', 'holiness', ' ', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'in', 'and', 'and', 'and', 'a', 'hard', 'hollow', 'occurred', 'a', 'a', 'awaken', 'about', 'number', 'a', 'a', 'other', 'other', 'other', 'a', 'in', 'tyrants', 'men', 'men', 'man', 'man', 'man', '<unk>', 'admit', 'broken', 'had', 'persuading', 'london', 'unburied', 'one', 'had', ' ', 'before', 'to', 'becomes', ' ', 'always', 'all', 'all', 'all', 'all', 'how', 'how', 'how', 'was', 'upon', ' ', ' ', 'the', 'thing', 'the', 'they', 'their', 'the', 'against', 'the', 'asked', 'with', 'saw', 'and', 'and', 'and', ' ', 'and', 'and', 'and', 'in', 'a', 'little', 'of', 'wakened', 'about', 'about', 'about', 'other', 'altogether', 'other', 'others', 'men', '<unk>', 'in', 'had', 'had', 'had', 'had', 'had', 'persuade', 'wait', 'on', 'one', 'one', 'one', 'one', 'had', 'had', 'has', 'public', 'bars', 'patriarch', \"opponent's\", 'before', 'before', 'generally', 'the', 'was', 'time', 'twister', 'quiet', 'terrible', 'case', 'chestnut', 'traitor', 'prepare', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'they', 'their', 'their', 'their', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'asked', 'with', 'in', 'in', 'begin', 'then', 'pale', 'little', 'little', 'little', 'little', 'little', 'awake', 'husband', 'public', 'generally', 'the', 'a', 'the', 'the', 'the', 'the', 'the', 'the', 'the', ' ', 'the', 'the', 'the', 'the', 'time', 'time', 'time', 'time', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'day', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'they', 'their', 'their', 'their', 'their', 'their', 'their', 'their', 'the', 'the', 'the', 'the', 'the', 'the', 'the', ' ', 'little', 'been', 'general', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'this', 'the', 'this', 'this', 'sometimes', 'day', 'the', 'the', 'they', 'they', 'their', 'been', 'been', 'been', 'the', 'the', 'this', 'this', 'this', 'days', 'quixote', 'this', 'this']\n",
      "\n",
      "Cluster 2\n",
      "['you', 'you', 'you', 'you', 'you', 'you', 'you']\n",
      "\n",
      "Cluster 3\n",
      "['mister', 'mister', 'mister', 'mister', 'miss', 'missus']\n",
      "\n",
      "Cluster 4\n",
      "['meekin']\n",
      "\n",
      "Cluster 5\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "\n",
      "Cluster 6\n",
      "['my', 'my', 'myself', 'my', 'my', 'my', 'himself', 'myself']\n",
      "\n",
      "Cluster 7\n",
      "['death', 'death', 'death']\n",
      "\n",
      "Cluster 8\n",
      "['pink', '<unk>']\n",
      "\n",
      "Cluster 9\n",
      "['marble']\n",
      "\n",
      "Cluster 10\n",
      "['statue', 'statues']\n",
      "\n",
      "Cluster 11\n",
      "['me', 'me', 'me', 'me', 'me']\n",
      "\n",
      "Cluster 12\n",
      "['will', 'will', 'will', 'will', 'would', 'shall', 'shall']\n",
      "\n",
      "Cluster 13\n",
      "['be', 'behold', 'be', 'be', 'be', 'be', 'becoming', 'coal', 'be', 'be', 'became', 'came', 'came', 'came', 'came', 'came', 'came', 'came', 'came']\n",
      "\n",
      "Cluster 14\n",
      "['set']\n",
      "\n",
      "Cluster 15\n",
      "['up', 'up', 'up', 'up', 'up', 'up', 'up', 'up']\n",
      "\n",
      "Cluster 16\n",
      "['grand']\n",
      "\n",
      "Cluster 17\n",
      "['court']\n",
      "\n",
      "Cluster 18\n",
      "['kings']\n",
      "\n",
      "Cluster 19\n",
      "['queens', 'queen']\n",
      "\n",
      "Cluster 20\n",
      "['who', 'who', 'who', 'who', 'who', 'who', 'who', 'who', 'whose', \"who's\"]\n",
      "\n",
      "Cluster 21\n",
      "['have']\n",
      "\n",
      "Cluster 22\n",
      "['ruled']\n",
      "\n",
      "Cluster 23\n",
      "['land']\n",
      "\n",
      "Cluster 24\n",
      "[' ']\n",
      "\n",
      "Cluster 25\n",
      "['and', 'and']\n",
      "\n",
      "Cluster 26\n",
      "['ages']\n",
      "\n",
      "Cluster 27\n",
      "['come']\n",
      "\n",
      "Cluster 28\n",
      "['will']\n",
      "\n",
      "Cluster 29\n",
      "['then']\n",
      "\n",
      "Cluster 30\n",
      "['honor']\n",
      "\n",
      "Cluster 31\n",
      "['having']\n",
      "\n",
      "Cluster 32\n",
      "['been']\n",
      "\n",
      "Cluster 33\n",
      "['a']\n",
      "\n",
      "Cluster 34\n",
      "['just']\n",
      "\n",
      "Cluster 35\n",
      "['upright']\n",
      "\n",
      "Cluster 36\n",
      "[' ']\n",
      "\n",
      "Cluster 37\n",
      "['that', \"that's\", 'that', \"that's\", \"that's\"]\n",
      "\n",
      "Cluster 38\n",
      "['reward']\n",
      "\n",
      "Cluster 39\n",
      "['but', 'but', 'but']\n",
      "\n",
      "Cluster 40\n",
      "['reality']\n",
      "\n",
      "Cluster 41\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 42\n",
      "['hansel']\n",
      "\n",
      "Cluster 43\n",
      "['not', 'not', 'not', 'not', 'nut', 'not', 'cannot', 'can', 'can', 'can', 'could', 'can', 'could', 'could', 'consider', 'confess']\n",
      "\n",
      "Cluster 44\n",
      "['looking']\n",
      "\n",
      "Cluster 45\n",
      "['at', 'out']\n",
      "\n",
      "Cluster 46\n",
      "['cat']\n",
      "\n",
      "Cluster 47\n",
      "[' ']\n",
      "\n",
      "Cluster 48\n",
      "['every', 'every', 'every', 'every']\n",
      "\n",
      "Cluster 49\n",
      "['he']\n",
      "\n",
      "Cluster 50\n",
      "['stopped']\n",
      "\n",
      "Cluster 51\n",
      "['he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he', 'he']\n",
      "\n",
      "Cluster 52\n",
      "['dropped']\n",
      "\n",
      "Cluster 53\n",
      "['pebble']\n",
      "\n",
      "Cluster 54\n",
      "['his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his', 'his']\n",
      "\n",
      "Cluster 55\n",
      "['pocket']\n",
      "\n",
      "Cluster 56\n",
      "['path']\n",
      "\n",
      "Cluster 57\n",
      "[' ']\n",
      "\n",
      "Cluster 58\n",
      "['walter']\n",
      "\n",
      "Cluster 59\n",
      "['gone', 'got']\n",
      "\n",
      "Cluster 60\n",
      "['out', 'outside', 'out', 'out', 'out']\n",
      "\n",
      "Cluster 61\n",
      "['second', 'seconds', 'second', 'second']\n",
      "\n",
      "Cluster 62\n",
      "[' ']\n",
      "\n",
      "Cluster 63\n",
      "['had']\n",
      "\n",
      "Cluster 64\n",
      "['gathered']\n",
      "\n",
      "Cluster 65\n",
      "['around', 'around']\n",
      "\n",
      "Cluster 66\n",
      "['camp']\n",
      "\n",
      "Cluster 67\n",
      "['fire', 'fireplace']\n",
      "\n",
      "Cluster 68\n",
      "['for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'for', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', ' ', 'from', 'finally', 'finished', 'frog', 'front', 'friend']\n",
      "\n",
      "Cluster 69\n",
      "['nightly']\n",
      "\n",
      "Cluster 70\n",
      "['story']\n",
      "\n",
      "Cluster 71\n",
      "['telling']\n",
      "\n",
      "Cluster 72\n",
      "['for']\n",
      "\n",
      "Cluster 73\n",
      "['when', 'when', 'when']\n",
      "\n",
      "Cluster 74\n",
      "['i', 'i', 'i', 'i', \"i'm\", 'i', 'i', \"i'm\", 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "\n",
      "Cluster 75\n",
      "['girl']\n",
      "\n",
      "Cluster 76\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 77\n",
      "['we']\n",
      "\n",
      "Cluster 78\n",
      "['logs']\n",
      "\n",
      "Cluster 79\n",
      "['wood']\n",
      "\n",
      "Cluster 80\n",
      "['blazing']\n",
      "\n",
      "Cluster 81\n",
      "['open']\n",
      "\n",
      "Cluster 82\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 83\n",
      "['so']\n",
      "\n",
      "Cluster 84\n",
      "[' ']\n",
      "\n",
      "Cluster 85\n",
      "['did']\n",
      "\n",
      "Cluster 86\n",
      "['people', 'people', 'people']\n",
      "\n",
      "Cluster 87\n",
      "['just']\n",
      "\n",
      "Cluster 88\n",
      "['coming']\n",
      "\n",
      "Cluster 89\n",
      "['use']\n",
      "\n",
      "Cluster 90\n",
      "['fuel']\n",
      "\n",
      "Cluster 91\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 92\n",
      "[\"don't\"]\n",
      "\n",
      "Cluster 93\n",
      "['move']\n",
      "\n",
      "Cluster 94\n",
      "['lie', 'like']\n",
      "\n",
      "Cluster 95\n",
      "['perfectly']\n",
      "\n",
      "Cluster 96\n",
      "['still']\n",
      "\n",
      "Cluster 97\n",
      "['warned']\n",
      "\n",
      "Cluster 98\n",
      "['guide']\n",
      "\n",
      "Cluster 99\n",
      "['are']\n",
      "\n",
      "Cluster 100\n",
      "['hurt']\n",
      "\n",
      "Cluster 101\n",
      "['vanity']\n",
      "\n",
      "Cluster 102\n",
      "['celestine']\n",
      "\n",
      "Cluster 103\n",
      "['flattered']\n",
      "\n",
      "Cluster 104\n",
      "['by', 'by', 'by', 'by', 'by', ' ', 'by']\n",
      "\n",
      "Cluster 105\n",
      "['appeal']\n",
      "\n",
      "Cluster 106\n",
      "['partial']\n",
      "\n",
      "Cluster 107\n",
      "['version']\n",
      "\n",
      "Cluster 108\n",
      "['monk']\n",
      "\n",
      "Cluster 109\n",
      "['decided']\n",
      "\n",
      "Cluster 110\n",
      "['faith', 'faint']\n",
      "\n",
      "Cluster 111\n",
      "['pope']\n",
      "\n",
      "Cluster 112\n",
      "['with']\n",
      "\n",
      "Cluster 113\n",
      "['latin']\n",
      "\n",
      "Cluster 114\n",
      "['clergy']\n",
      "\n",
      "Cluster 115\n",
      "['ignorant']\n",
      "\n",
      "Cluster 116\n",
      "['language']\n",
      "\n",
      "Cluster 117\n",
      "['arts']\n",
      "\n",
      "Cluster 118\n",
      "['theology']\n",
      "\n",
      "Cluster 119\n",
      "['greeks']\n",
      "\n",
      "Cluster 120\n",
      "['tad']\n",
      "\n",
      "Cluster 121\n",
      "['experienced', 'experience']\n",
      "\n",
      "Cluster 122\n",
      "['rider']\n",
      "\n",
      "Cluster 123\n",
      "['here', 'here', 'here']\n",
      "\n",
      "Cluster 124\n",
      "['well', 'well']\n",
      "\n",
      "Cluster 125\n",
      "['places', 'prices']\n",
      "\n",
      "Cluster 126\n",
      "['one']\n",
      "\n",
      "Cluster 127\n",
      "['appreciate']\n",
      "\n",
      "Cluster 128\n",
      "['colloquial']\n",
      "\n",
      "Cluster 129\n",
      "['definition']\n",
      "\n",
      "Cluster 130\n",
      "['cabaret']\n",
      "\n",
      "Cluster 131\n",
      "['coughed']\n",
      "\n",
      "Cluster 132\n",
      "[' ']\n",
      "\n",
      "Cluster 133\n",
      "['drank']\n",
      "\n",
      "Cluster 134\n",
      "['tea']\n",
      "\n",
      "Cluster 135\n",
      "['endeavoured']\n",
      "\n",
      "Cluster 136\n",
      "['talk']\n",
      "\n",
      "Cluster 137\n",
      "['but']\n",
      "\n",
      "Cluster 138\n",
      "['found', 'found']\n",
      "\n",
      "Cluster 139\n",
      "['it', 'it', 'it', 'it', 'it', 'at', 'it', 'it', 'it', 'it', 'it', 'it', 'at', 'it', 'its', 'its', 'its', 'its', 'its']\n",
      "\n",
      "Cluster 140\n",
      "['difficult']\n",
      "\n",
      "Cluster 141\n",
      "['read']\n",
      "\n",
      "Cluster 142\n",
      "[' ']\n",
      "\n",
      "Cluster 143\n",
      "['manner']\n",
      "\n",
      "Cluster 144\n",
      "['near']\n",
      "\n",
      "Cluster 145\n",
      "['hours']\n",
      "\n",
      "Cluster 146\n",
      "['passed', 'passed']\n",
      "\n",
      "Cluster 147\n",
      "['away', 'away']\n",
      "\n",
      "Cluster 148\n",
      "['when']\n",
      "\n",
      "Cluster 149\n",
      "['milner']\n",
      "\n",
      "Cluster 150\n",
      "['room', 'rome']\n",
      "\n",
      "Cluster 151\n",
      "[' ']\n",
      "\n",
      "Cluster 152\n",
      "['not']\n",
      "\n",
      "Cluster 153\n",
      "[' ']\n",
      "\n",
      "Cluster 154\n",
      "['dressed']\n",
      "\n",
      "Cluster 155\n",
      "['ball']\n",
      "\n",
      "Cluster 156\n",
      "['but', 'but', 'but']\n",
      "\n",
      "Cluster 157\n",
      "['she', 'she', 'she', 'she', 'she', 'she', 'she', 'she']\n",
      "\n",
      "Cluster 158\n",
      "['risen']\n",
      "\n",
      "Cluster 159\n",
      "['dinner']\n",
      "\n",
      "Cluster 160\n",
      "['fetid']\n",
      "\n",
      "Cluster 161\n",
      "['smell']\n",
      "\n",
      "Cluster 162\n",
      "['him', 'him', 'him', 'her', 'her']\n",
      "\n",
      "Cluster 163\n",
      "[' ']\n",
      "\n",
      "Cluster 164\n",
      "['green']\n",
      "\n",
      "Cluster 165\n",
      "['oozed']\n",
      "\n",
      "Cluster 166\n",
      "['crushed']\n",
      "\n",
      "Cluster 167\n",
      "['head']\n",
      "\n",
      "Cluster 168\n",
      "['clarets', 'claret']\n",
      "\n",
      "Cluster 169\n",
      "['are', 'are', 'are', 'are', 'are', 'are']\n",
      "\n",
      "Cluster 170\n",
      "['valued', 'values']\n",
      "\n",
      "Cluster 171\n",
      "['flavor', 'flavour']\n",
      "\n",
      "Cluster 172\n",
      "['tonic']\n",
      "\n",
      "Cluster 173\n",
      "['properties']\n",
      "\n",
      "Cluster 174\n",
      "['kingdom', 'kingdoms']\n",
      "\n",
      "Cluster 175\n",
      "['northumbria', 'northumbria']\n",
      "\n",
      "Cluster 176\n",
      "['name', 'neighbour', 'name', 'neighbours']\n",
      "\n",
      "Cluster 177\n",
      "['implies']\n",
      "\n",
      "Cluster 178\n",
      "['embraced']\n",
      "\n",
      "Cluster 179\n",
      "['nearly']\n",
      "\n",
      "Cluster 180\n",
      "['country']\n",
      "\n",
      "Cluster 181\n",
      "['humber']\n",
      "\n",
      "Cluster 182\n",
      "['pictish']\n",
      "\n",
      "Cluster 183\n",
      "['border']\n",
      "\n",
      "Cluster 184\n",
      "['otto']\n",
      "\n",
      "Cluster 185\n",
      "['winked']\n",
      "\n",
      "Cluster 186\n",
      "['at']\n",
      "\n",
      "Cluster 187\n",
      "['mood']\n",
      "\n",
      "Cluster 188\n",
      "['music']\n",
      "\n",
      "Cluster 189\n",
      "['not']\n",
      "\n",
      "Cluster 190\n",
      "['dread']\n",
      "\n",
      "Cluster 191\n",
      "['led', 'led']\n",
      "\n",
      "Cluster 192\n",
      "['him']\n",
      "\n",
      "Cluster 193\n",
      "['make', 'make']\n",
      "\n",
      "Cluster 194\n",
      "['remark']\n",
      "\n",
      "Cluster 195\n",
      "['that']\n",
      "\n",
      "Cluster 196\n",
      "['stevie']\n",
      "\n",
      "Cluster 197\n",
      "['disregarded', 'regarded']\n",
      "\n",
      "Cluster 198\n",
      "['suggestion']\n",
      "\n",
      "Cluster 199\n",
      "['go', 'go']\n",
      "\n",
      "Cluster 200\n",
      "['to']\n",
      "\n",
      "Cluster 201\n",
      "['bed']\n",
      "\n",
      "Cluster 202\n",
      "['not']\n",
      "\n",
      "Cluster 203\n",
      "['david', 'david']\n",
      "\n",
      "Cluster 204\n",
      "[' ']\n",
      "\n",
      "Cluster 205\n",
      "['true']\n",
      "\n",
      "Cluster 206\n",
      "['love']\n",
      "\n",
      "Cluster 207\n",
      "['christie']\n",
      "\n",
      "Cluster 208\n",
      "['now', 'now', 'now', 'now', 'now']\n",
      "\n",
      "Cluster 209\n",
      "['burned']\n",
      "\n",
      "Cluster 210\n",
      "['both', 'both', 'both']\n",
      "\n",
      "Cluster 211\n",
      "['sides', 'side']\n",
      "\n",
      "Cluster 212\n",
      "['lay']\n",
      "\n",
      "Cluster 213\n",
      "['still']\n",
      "\n",
      "Cluster 214\n",
      "['hot']\n",
      "\n",
      "Cluster 215\n",
      "['along']\n",
      "\n",
      "Cluster 216\n",
      "['edges']\n",
      "\n",
      "Cluster 217\n",
      "['on']\n",
      "\n",
      "Cluster 218\n",
      "['floor', 'flowery']\n",
      "\n",
      "Cluster 219\n",
      "['big', 'big', 'big']\n",
      "\n",
      "Cluster 220\n",
      "['office', 'sophists']\n",
      "\n",
      "Cluster 221\n",
      "['room', 'room']\n",
      "\n",
      "Cluster 222\n",
      "['in']\n",
      "\n",
      "Cluster 223\n",
      "[' ']\n",
      "\n",
      "Cluster 224\n",
      "['something', 'something', 'something']\n",
      "\n",
      "Cluster 225\n",
      "['different']\n",
      "\n",
      "Cluster 226\n",
      "['rounded']\n",
      "\n",
      "Cluster 227\n",
      "['shell']\n",
      "\n",
      "Cluster 228\n",
      "['split']\n",
      "\n",
      "Cluster 229\n",
      "['off']\n",
      "\n",
      "Cluster 230\n",
      "['there']\n",
      "\n",
      "Cluster 231\n",
      "['is']\n",
      "\n",
      "Cluster 232\n",
      "['nut']\n",
      "\n",
      "Cluster 233\n",
      "['lying']\n",
      "\n",
      "Cluster 234\n",
      "['snugly']\n",
      "\n",
      "Cluster 235\n",
      "[' ']\n",
      "\n",
      "Cluster 236\n",
      "['bur']\n",
      "\n",
      "Cluster 237\n",
      "['it']\n",
      "\n",
      "Cluster 238\n",
      "['contained']\n",
      "\n",
      "Cluster 239\n",
      "['only', 'only']\n",
      "\n",
      "Cluster 240\n",
      "['chanticleer']\n",
      "\n",
      "Cluster 241\n",
      "[' ']\n",
      "\n",
      "Cluster 242\n",
      "['his']\n",
      "\n",
      "Cluster 243\n",
      "['wives']\n",
      "\n",
      "Cluster 244\n",
      "[' ']\n",
      "\n",
      "Cluster 245\n",
      "['solitary']\n",
      "\n",
      "Cluster 246\n",
      "['chicken']\n",
      "\n",
      "Cluster 247\n",
      "[' ']\n",
      "\n",
      "Cluster 248\n",
      "['on']\n",
      "\n",
      "Cluster 249\n",
      "['month']\n",
      "\n",
      "Cluster 250\n",
      "[' ']\n",
      "\n",
      "Cluster 251\n",
      "['morning']\n",
      "\n",
      "Cluster 252\n",
      "[' ']\n",
      "\n",
      "Cluster 253\n",
      "['our']\n",
      "\n",
      "Cluster 254\n",
      "['precious']\n",
      "\n",
      "Cluster 255\n",
      "['cargo']\n",
      "\n",
      "Cluster 256\n",
      "['luggage']\n",
      "\n",
      "Cluster 257\n",
      "['taken']\n",
      "\n",
      "Cluster 258\n",
      "['board']\n",
      "\n",
      "Cluster 259\n",
      "['good', 'good']\n",
      "\n",
      "Cluster 260\n",
      "['ship']\n",
      "\n",
      "Cluster 261\n",
      "['valkyrie']\n",
      "\n",
      "Cluster 262\n",
      "['whichever']\n",
      "\n",
      "Cluster 263\n",
      "['groups']\n",
      "\n",
      "Cluster 264\n",
      "['sensations']\n",
      "\n",
      "Cluster 265\n",
      "['a']\n",
      "\n",
      "Cluster 266\n",
      "['soul']\n",
      "\n",
      "Cluster 267\n",
      "['most', 'most', 'most']\n",
      "\n",
      "Cluster 268\n",
      "['readily']\n",
      "\n",
      "Cluster 269\n",
      "['speak', 'speaks', 'speak']\n",
      "\n",
      "Cluster 270\n",
      "['and', 'an']\n",
      "\n",
      "Cluster 271\n",
      "['give', 'give']\n",
      "\n",
      "Cluster 272\n",
      "['word']\n",
      "\n",
      "Cluster 273\n",
      "['command']\n",
      "\n",
      "Cluster 274\n",
      "['these']\n",
      "\n",
      "Cluster 275\n",
      "['decide']\n",
      "\n",
      "Cluster 276\n",
      "['rank']\n",
      "\n",
      "Cluster 277\n",
      "['determine']\n",
      "\n",
      "Cluster 278\n",
      "['list']\n",
      "\n",
      "Cluster 279\n",
      "['desirable']\n",
      "\n",
      "Cluster 280\n",
      "['things']\n",
      "\n",
      "Cluster 281\n",
      "['scared']\n",
      "\n",
      "Cluster 282\n",
      "[' ']\n",
      "\n",
      "Cluster 283\n",
      "['dah']\n",
      "\n",
      "Cluster 284\n",
      "[' ']\n",
      "\n",
      "Cluster 285\n",
      "['afraid', 'afraid']\n",
      "\n",
      "Cluster 286\n",
      "[' ']\n",
      "\n",
      "Cluster 287\n",
      "['answered']\n",
      "\n",
      "Cluster 288\n",
      "['he']\n",
      "\n",
      "Cluster 289\n",
      "[' ']\n",
      "\n",
      "Cluster 290\n",
      "['more', 'more', 'more']\n",
      "\n",
      "Cluster 291\n",
      "['sure', 'short', 'shirt', 'surely', 'shirking']\n",
      "\n",
      "Cluster 292\n",
      "['footed']\n",
      "\n",
      "Cluster 293\n",
      "['ned']\n",
      "\n",
      "Cluster 294\n",
      "['said']\n",
      "\n",
      "Cluster 295\n",
      "['that']\n",
      "\n",
      "Cluster 296\n",
      "['trip']\n",
      "\n",
      "Cluster 297\n",
      "['was']\n",
      "\n",
      "Cluster 298\n",
      "[' ']\n",
      "\n",
      "Cluster 299\n",
      "['jimmie']\n",
      "\n",
      "Cluster 300\n",
      "['would']\n",
      "\n",
      "Cluster 301\n",
      "['able']\n",
      "\n",
      "Cluster 302\n",
      "['walk', 'walked', ' ', 'check', 'asked', 'asked']\n",
      "\n",
      "Cluster 303\n",
      "['a']\n",
      "\n",
      "Cluster 304\n",
      "['slack']\n",
      "\n",
      "Cluster 305\n",
      "['rope']\n",
      "\n",
      "Cluster 306\n",
      "['only']\n",
      "\n",
      "Cluster 307\n",
      "['whatever']\n",
      "\n",
      "Cluster 308\n",
      "['have', 'half']\n",
      "\n",
      "Cluster 309\n",
      "['thee']\n",
      "\n",
      "Cluster 310\n",
      "['lige']\n",
      "\n",
      "Cluster 311\n",
      "['quickly', 'quickly']\n",
      "\n",
      "Cluster 312\n",
      "['made']\n",
      "\n",
      "Cluster 313\n",
      "['fast']\n",
      "\n",
      "Cluster 314\n",
      "['line', 'lining']\n",
      "\n",
      "Cluster 315\n",
      "['a']\n",
      "\n",
      "Cluster 316\n",
      "['tree', 'tree', 'tree']\n",
      "\n",
      "Cluster 317\n",
      "[\"i'm\"]\n",
      "\n",
      "Cluster 318\n",
      "['said', 'said', 'says']\n",
      "\n",
      "Cluster 319\n",
      "['sailing']\n",
      "\n",
      "Cluster 320\n",
      "['master']\n",
      "\n",
      "Cluster 321\n",
      "['announced']\n",
      "\n",
      "Cluster 322\n",
      "['that', 'that', 'that', 'that', 'that', 'that', 'that', 'that']\n",
      "\n",
      "Cluster 323\n",
      "['had']\n",
      "\n",
      "Cluster 324\n",
      "['orders']\n",
      "\n",
      "Cluster 325\n",
      "['take']\n",
      "\n",
      "Cluster 326\n",
      "['vessel']\n",
      "\n",
      "Cluster 327\n",
      "['back']\n",
      "\n",
      "Cluster 328\n",
      "[' ']\n",
      "\n",
      "Cluster 329\n",
      "['port']\n",
      "\n",
      "Cluster 330\n",
      "['no']\n",
      "\n",
      "Cluster 331\n",
      "['explanation']\n",
      "\n",
      "Cluster 332\n",
      "['than']\n",
      "\n",
      "Cluster 333\n",
      "['cruise']\n",
      "\n",
      "Cluster 334\n",
      "['over']\n",
      "\n",
      "Cluster 335\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 336\n",
      "['i', 'i']\n",
      "\n",
      "Cluster 337\n",
      "['remained', 'remained']\n",
      "\n",
      "Cluster 338\n",
      "['night']\n",
      "\n",
      "Cluster 339\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 340\n",
      "['talking']\n",
      "\n",
      "Cluster 341\n",
      "['comrade']\n",
      "\n",
      "Cluster 342\n",
      "['shared']\n",
      "\n",
      "Cluster 343\n",
      "['blanket']\n",
      "\n",
      "Cluster 344\n",
      "[' ']\n",
      "\n",
      "Cluster 345\n",
      "['poor']\n",
      "\n",
      "Cluster 346\n",
      "['jimmy']\n",
      "\n",
      "Cluster 347\n",
      "['king']\n",
      "\n",
      "Cluster 348\n",
      "['of']\n",
      "\n",
      "Cluster 349\n",
      "['course']\n",
      "\n",
      "Cluster 350\n",
      "['hilda']\n",
      "\n",
      "Cluster 351\n",
      "['irish', 'irish']\n",
      "\n",
      "Cluster 352\n",
      "[' ']\n",
      "\n",
      "Cluster 353\n",
      "['the']\n",
      "\n",
      "Cluster 354\n",
      "['<unk>']\n",
      "\n",
      "Cluster 355\n",
      "['have', 'have']\n",
      "\n",
      "Cluster 356\n",
      "['stage']\n",
      "\n",
      "Cluster 357\n",
      "['generations', 'generation']\n",
      "\n",
      "Cluster 358\n",
      "[' ']\n",
      "\n",
      "Cluster 359\n",
      "['voice']\n",
      "\n",
      "Cluster 360\n",
      "['almost', 'almost']\n",
      "\n",
      "Cluster 361\n",
      "['exclaimed', 'exclaimed', 'explain']\n",
      "\n",
      "Cluster 362\n",
      "['loud']\n",
      "\n",
      "Cluster 363\n",
      "['at', 'at']\n",
      "\n",
      "Cluster 364\n",
      "['insistency']\n",
      "\n",
      "Cluster 365\n",
      "[' ']\n",
      "\n",
      "Cluster 366\n",
      "['serve']\n",
      "\n",
      "Cluster 367\n",
      "['spanish']\n",
      "\n",
      "Cluster 368\n",
      "['reasonable']\n",
      "\n",
      "Cluster 369\n",
      "['feeble']\n",
      "\n",
      "Cluster 370\n",
      "['son']\n",
      "\n",
      "Cluster 371\n",
      "['arcadius']\n",
      "\n",
      "Cluster 372\n",
      "['swayed']\n",
      "\n",
      "Cluster 373\n",
      "['wife', 'wife']\n",
      "\n",
      "Cluster 374\n",
      "['sister']\n",
      "\n",
      "Cluster 375\n",
      "['by']\n",
      "\n",
      "Cluster 376\n",
      "['eunuchs']\n",
      "\n",
      "Cluster 377\n",
      "['women', 'woman']\n",
      "\n",
      "Cluster 378\n",
      "['palace', 'palace']\n",
      "\n",
      "Cluster 379\n",
      "['superstition']\n",
      "\n",
      "Cluster 380\n",
      "['ruling']\n",
      "\n",
      "Cluster 381\n",
      "['passions']\n",
      "\n",
      "Cluster 382\n",
      "['chiefs']\n",
      "\n",
      "Cluster 383\n",
      "['assiduous']\n",
      "\n",
      "Cluster 384\n",
      "['endeavors']\n",
      "\n",
      "Cluster 385\n",
      "['former']\n",
      "\n",
      "Cluster 386\n",
      "['gratify']\n",
      "\n",
      "Cluster 387\n",
      "['latter']\n",
      "\n",
      "Cluster 388\n",
      "['does']\n",
      "\n",
      "Cluster 389\n",
      "['samuel']\n",
      "\n",
      "Cluster 390\n",
      "['live', 'live']\n",
      "\n",
      "Cluster 391\n",
      "['trevelyan']\n",
      "\n",
      "Cluster 392\n",
      "['grant', 'grant']\n",
      "\n",
      "Cluster 393\n",
      "['acted']\n",
      "\n",
      "Cluster 394\n",
      "['mustering']\n",
      "\n",
      "Cluster 395\n",
      "['officer']\n",
      "\n",
      "Cluster 396\n",
      "['commissioned']\n",
      "\n",
      "Cluster 397\n",
      "['colonel']\n",
      "\n",
      "Cluster 398\n",
      "['the']\n",
      "\n",
      "Cluster 399\n",
      "[' ']\n",
      "\n",
      "Cluster 400\n",
      "['twenty', 'twenties']\n",
      "\n",
      "Cluster 401\n",
      "['first', 'first']\n",
      "\n",
      "Cluster 402\n",
      "['volunteers']\n",
      "\n",
      "Cluster 403\n",
      "['took']\n",
      "\n",
      "Cluster 404\n",
      "['field']\n",
      "\n",
      "Cluster 405\n",
      "['minnie']\n",
      "\n",
      "Cluster 406\n",
      "['began']\n",
      "\n",
      "Cluster 407\n",
      "['her']\n",
      "\n",
      "Cluster 408\n",
      "['took']\n",
      "\n",
      "Cluster 409\n",
      "['part', 'partly']\n",
      "\n",
      "Cluster 410\n",
      "['conversation']\n",
      "\n",
      "Cluster 411\n",
      "['a']\n",
      "\n",
      "Cluster 412\n",
      "['temporary']\n",
      "\n",
      "Cluster 413\n",
      "['camp']\n",
      "\n",
      "Cluster 414\n",
      "['pitched']\n",
      "\n",
      "Cluster 415\n",
      "['no']\n",
      "\n",
      "Cluster 416\n",
      "['battery']\n",
      "\n",
      "Cluster 417\n",
      "['whole']\n",
      "\n",
      "Cluster 418\n",
      "['four', 'four']\n",
      "\n",
      "Cluster 419\n",
      "['years']\n",
      "\n",
      "Cluster 420\n",
      "['war']\n",
      "\n",
      "Cluster 421\n",
      "['lost']\n",
      "\n",
      "Cluster 422\n",
      "['so', 'so', 'so', 'so']\n",
      "\n",
      "Cluster 423\n",
      "['many']\n",
      "\n",
      "Cluster 424\n",
      "['a']\n",
      "\n",
      "Cluster 425\n",
      "['catch']\n",
      "\n",
      "Cluster 426\n",
      "['train']\n",
      "\n",
      "Cluster 427\n",
      "['bring', 'bring']\n",
      "\n",
      "Cluster 428\n",
      "['my']\n",
      "\n",
      "Cluster 429\n",
      "['mother', 'mother']\n",
      "\n",
      "Cluster 430\n",
      "['morrow']\n",
      "\n",
      "Cluster 431\n",
      "['we']\n",
      "\n",
      "Cluster 432\n",
      "['what']\n",
      "\n",
      "Cluster 433\n",
      "['done']\n",
      "\n",
      "Cluster 434\n",
      "[' ']\n",
      "\n",
      "Cluster 435\n",
      "['fall']\n",
      "\n",
      "Cluster 436\n",
      "['to']\n",
      "\n",
      "Cluster 437\n",
      "['young']\n",
      "\n",
      "Cluster 438\n",
      "['gentlemen']\n",
      "\n",
      "Cluster 439\n",
      "['directed']\n",
      "\n",
      "Cluster 440\n",
      "['professor']\n",
      "\n",
      "Cluster 441\n",
      "['did']\n",
      "\n",
      "Cluster 442\n",
      "['drouet']\n",
      "\n",
      "Cluster 443\n",
      "['it']\n",
      "\n",
      "Cluster 444\n",
      "['never']\n",
      "\n",
      "Cluster 445\n",
      "['once']\n",
      "\n",
      "Cluster 446\n",
      "['worry', 'worried']\n",
      "\n",
      "Cluster 447\n",
      "['finding']\n",
      "\n",
      "Cluster 448\n",
      "['astonishment']\n",
      "\n",
      "Cluster 449\n",
      "['which', 'which']\n",
      "\n",
      "Cluster 450\n",
      "['villagers']\n",
      "\n",
      "Cluster 451\n",
      "['machine']\n",
      "\n",
      "Cluster 452\n",
      "['overwhelming']\n",
      "\n",
      "Cluster 453\n",
      "['saxons']\n",
      "\n",
      "Cluster 454\n",
      "['southern']\n",
      "\n",
      "Cluster 455\n",
      "['converted']\n",
      "\n",
      "Cluster 456\n",
      "['missionaries']\n",
      "\n",
      "Cluster 457\n",
      "['france']\n",
      "\n",
      "Cluster 458\n",
      "['or']\n",
      "\n",
      "Cluster 459\n",
      "[' ']\n",
      "\n",
      "Cluster 460\n",
      "['or', 'or']\n",
      "\n",
      "Cluster 461\n",
      "['native', 'native']\n",
      "\n",
      "Cluster 462\n",
      "['preachers']\n",
      "\n",
      "Cluster 463\n",
      "['christian']\n",
      "\n",
      "Cluster 464\n",
      "[' ']\n",
      "\n",
      "Cluster 465\n",
      "['those']\n",
      "\n",
      "Cluster 466\n",
      "['apostles']\n",
      "\n",
      "Cluster 467\n",
      "['aidan']\n",
      "\n",
      "Cluster 468\n",
      "['saint']\n",
      "\n",
      "Cluster 469\n",
      "['cuthbert']\n",
      "\n",
      "Cluster 470\n",
      "['fathers']\n",
      "\n",
      "Cluster 471\n",
      "['iona']\n",
      "\n",
      "Cluster 472\n",
      "['last', 'last']\n",
      "\n",
      "Cluster 473\n",
      "['intolerable']\n",
      "\n",
      "Cluster 474\n",
      "['peter']\n",
      "\n",
      "Cluster 475\n",
      "['moment']\n",
      "\n",
      "Cluster 476\n",
      "[' ']\n",
      "\n",
      "Cluster 477\n",
      "['back']\n",
      "\n",
      "Cluster 478\n",
      "['kitchen']\n",
      "\n",
      "Cluster 479\n",
      "['brought']\n",
      "\n",
      "Cluster 480\n",
      "['bag', 'bad']\n",
      "\n",
      "Cluster 481\n",
      "['sandwiches']\n",
      "\n",
      "Cluster 482\n",
      "['doughnuts']\n",
      "\n",
      "Cluster 483\n",
      "['us', 'us']\n",
      "\n",
      "Cluster 484\n",
      "['where']\n",
      "\n",
      "Cluster 485\n",
      "['each']\n",
      "\n",
      "Cluster 486\n",
      "['bird']\n",
      "\n",
      "Cluster 487\n",
      "['perched']\n",
      "\n",
      "Cluster 488\n",
      "['there']\n",
      "\n",
      "Cluster 489\n",
      "['build']\n",
      "\n",
      "Cluster 490\n",
      "['nest']\n",
      "\n",
      "Cluster 491\n",
      "['meanwhile']\n",
      "\n",
      "Cluster 492\n",
      "['rest']\n",
      "\n",
      "Cluster 493\n",
      "['castle']\n",
      "\n",
      "Cluster 494\n",
      "['same']\n",
      "\n",
      "Cluster 495\n",
      "['moment']\n",
      "\n",
      "Cluster 496\n",
      "['princess']\n",
      "\n",
      "Cluster 497\n",
      "[' ']\n",
      "\n",
      "Cluster 498\n",
      "['extremely']\n",
      "\n",
      "Cluster 499\n",
      "['hungry']\n",
      "\n",
      "Cluster 500\n",
      "[' ']\n",
      "\n",
      "Cluster 501\n",
      "['mule']\n",
      "\n",
      "Cluster 502\n",
      "['did', 'did']\n",
      "\n",
      "Cluster 503\n",
      "['desire', 'desires', 'desire']\n",
      "\n",
      "Cluster 504\n",
      "['cross']\n",
      "\n",
      "Cluster 505\n",
      "[' ']\n",
      "\n",
      "Cluster 506\n",
      "['while']\n",
      "\n",
      "Cluster 507\n",
      "['trying']\n",
      "\n",
      "Cluster 508\n",
      "['him']\n",
      "\n",
      "Cluster 509\n",
      "['a']\n",
      "\n",
      "Cluster 510\n",
      "['stick']\n",
      "\n",
      "Cluster 511\n",
      "[' ']\n",
      "\n",
      "Cluster 512\n",
      "['rock']\n",
      "\n",
      "Cluster 513\n",
      "['ear']\n",
      "\n",
      "Cluster 514\n",
      "['a']\n",
      "\n",
      "Cluster 515\n",
      "['nose']\n",
      "\n",
      "Cluster 516\n",
      "['none']\n",
      "\n",
      "Cluster 517\n",
      "['might']\n",
      "\n",
      "Cluster 518\n",
      "['exhort']\n",
      "\n",
      "Cluster 519\n",
      "['in']\n",
      "\n",
      "Cluster 520\n",
      "['way']\n",
      "\n",
      "Cluster 521\n",
      "['meddle']\n",
      "\n",
      "Cluster 522\n",
      "['religious']\n",
      "\n",
      "Cluster 523\n",
      "['house']\n",
      "\n",
      "Cluster 524\n",
      "['hillside']\n",
      "\n",
      "Cluster 525\n",
      "['much', 'much']\n",
      "\n",
      "Cluster 526\n",
      "['color', 'colored']\n",
      "\n",
      "Cluster 527\n",
      "['we', 'we', 'we', 'we', 'we']\n",
      "\n",
      "Cluster 528\n",
      "['draw']\n",
      "\n",
      "Cluster 529\n",
      "['produced']\n",
      "\n",
      "Cluster 530\n",
      "['collection']\n",
      "\n",
      "Cluster 531\n",
      "['brilliantly']\n",
      "\n",
      "Cluster 532\n",
      "['paper']\n",
      "\n",
      "Cluster 533\n",
      "['figures']\n",
      "\n",
      "Cluster 534\n",
      "['inches']\n",
      "\n",
      "Cluster 535\n",
      "['high']\n",
      "\n",
      "Cluster 536\n",
      "[' ']\n",
      "\n",
      "Cluster 537\n",
      "['stiff']\n",
      "\n",
      "Cluster 538\n",
      "['enough']\n",
      "\n",
      "Cluster 539\n",
      "['stand']\n",
      "\n",
      "Cluster 540\n",
      "['alone']\n",
      "\n",
      "Cluster 541\n",
      "['very']\n",
      "\n",
      "Cluster 542\n",
      "['wrapped']\n",
      "\n",
      "Cluster 543\n",
      "['offspring']\n",
      "\n",
      "Cluster 544\n",
      "[\"it's\"]\n",
      "\n",
      "Cluster 545\n",
      "['storm']\n",
      "\n",
      "Cluster 546\n",
      "['said']\n",
      "\n",
      "Cluster 547\n",
      "[\"merchant's\"]\n",
      "\n",
      "Cluster 548\n",
      "['daughter']\n",
      "\n",
      "Cluster 549\n",
      "['wind']\n",
      "\n",
      "Cluster 550\n",
      "['rattled']\n",
      "\n",
      "Cluster 551\n",
      "['tiles']\n",
      "\n",
      "Cluster 552\n",
      "['roof']\n",
      "\n",
      "Cluster 553\n",
      "['rain', 'reigned']\n",
      "\n",
      "Cluster 554\n",
      "['beat']\n",
      "\n",
      "Cluster 555\n",
      "['torrents']\n",
      "\n",
      "Cluster 556\n",
      "['doors']\n",
      "\n",
      "Cluster 557\n",
      "['windows']\n",
      "\n",
      "Cluster 558\n",
      "[\"we've\"]\n",
      "\n",
      "Cluster 559\n",
      "['drive']\n",
      "\n",
      "Cluster 560\n",
      "['us']\n",
      "\n",
      "Cluster 561\n",
      "['and']\n",
      "\n",
      "Cluster 562\n",
      "['must']\n",
      "\n",
      "Cluster 563\n",
      "['fit']\n",
      "\n",
      "Cluster 564\n",
      "['fiddle']\n",
      "\n",
      "Cluster 565\n",
      "['danger', 'danger']\n",
      "\n",
      "Cluster 566\n",
      "['again', 'again']\n",
      "\n",
      "Cluster 567\n",
      "['present', 'presents']\n",
      "\n",
      "Cluster 568\n",
      "['morality']\n",
      "\n",
      "Cluster 569\n",
      "['great']\n",
      "\n",
      "Cluster 570\n",
      "['shifted']\n",
      "\n",
      "Cluster 571\n",
      "['individual']\n",
      "\n",
      "Cluster 572\n",
      "['street']\n",
      "\n",
      "Cluster 573\n",
      "['own', 'own', 'own']\n",
      "\n",
      "Cluster 574\n",
      "['child']\n",
      "\n",
      "Cluster 575\n",
      "['heart']\n",
      "\n",
      "Cluster 576\n",
      "['personal']\n",
      "\n",
      "Cluster 577\n",
      "['secret']\n",
      "\n",
      "Cluster 578\n",
      "['recesses']\n",
      "\n",
      "Cluster 579\n",
      "['volitions']\n",
      "\n",
      "Cluster 580\n",
      "['we']\n",
      "\n",
      "Cluster 581\n",
      "['at']\n",
      "\n",
      "Cluster 582\n",
      "['that', 'that']\n",
      "\n",
      "Cluster 583\n",
      "['least']\n",
      "\n",
      "Cluster 584\n",
      "['hundred']\n",
      "\n",
      "Cluster 585\n",
      "['yards']\n",
      "\n",
      "Cluster 586\n",
      "['advance']\n",
      "\n",
      "Cluster 587\n",
      "['brigade']\n",
      "\n",
      "Cluster 588\n",
      "['cheatham']\n",
      "\n",
      "Cluster 589\n",
      "['calling']\n",
      "\n",
      "Cluster 590\n",
      "['come', 'come']\n",
      "\n",
      "Cluster 591\n",
      "['on']\n",
      "\n",
      "Cluster 592\n",
      "['i']\n",
      "\n",
      "Cluster 593\n",
      "['believe', 'believe']\n",
      "\n",
      "Cluster 594\n",
      "['seriousness']\n",
      "\n",
      "Cluster 595\n",
      "['americans']\n",
      "\n",
      "Cluster 596\n",
      "['arises']\n",
      "\n",
      "Cluster 597\n",
      "['pride']\n",
      "\n",
      "Cluster 598\n",
      "['hello']\n",
      "\n",
      "Cluster 599\n",
      "['boys', 'boys']\n",
      "\n",
      "Cluster 600\n",
      "[' ']\n",
      "\n",
      "Cluster 601\n",
      "['what']\n",
      "\n",
      "Cluster 602\n",
      "['boss']\n",
      "\n",
      "Cluster 603\n",
      "[' ']\n",
      "\n",
      "Cluster 604\n",
      "['handler']\n",
      "\n",
      "Cluster 605\n",
      "['was']\n",
      "\n",
      "Cluster 606\n",
      "['kneading']\n",
      "\n",
      "Cluster 607\n",
      "['aching']\n",
      "\n",
      "Cluster 608\n",
      "['muscles']\n",
      "\n",
      "Cluster 609\n",
      "[' ']\n",
      "\n",
      "Cluster 610\n",
      "['i']\n",
      "\n",
      "Cluster 611\n",
      "['think', 'think']\n",
      "\n",
      "Cluster 612\n",
      "['right']\n",
      "\n",
      "Cluster 613\n",
      "[' ']\n",
      "\n",
      "Cluster 614\n",
      "['for']\n",
      "\n",
      "Cluster 615\n",
      "['either']\n",
      "\n",
      "Cluster 616\n",
      "['till']\n",
      "\n",
      "Cluster 617\n",
      "['downright']\n",
      "\n",
      "Cluster 618\n",
      "['cross']\n",
      "\n",
      "Cluster 619\n",
      "['or']\n",
      "\n",
      "Cluster 620\n",
      "['else']\n",
      "\n",
      "Cluster 621\n",
      "['just', 'just']\n",
      "\n",
      "Cluster 622\n",
      "['natural']\n",
      "\n",
      "Cluster 623\n",
      "['and']\n",
      "\n",
      "Cluster 624\n",
      "['kind']\n",
      "\n",
      "Cluster 625\n",
      "['tender']\n",
      "\n",
      "Cluster 626\n",
      "['ask']\n",
      "\n",
      "Cluster 627\n",
      "[' ']\n",
      "\n",
      "Cluster 628\n",
      "['beyond']\n",
      "\n",
      "Cluster 629\n",
      "['stood']\n",
      "\n",
      "Cluster 630\n",
      "['oak']\n",
      "\n",
      "Cluster 631\n",
      "['on']\n",
      "\n",
      "Cluster 632\n",
      "['battlefield']\n",
      "\n",
      "Cluster 633\n",
      "['among']\n",
      "\n",
      "Cluster 634\n",
      "['dead', 'dead', 'wed', 'dead']\n",
      "\n",
      "Cluster 635\n",
      "['swift', 'swift']\n",
      "\n",
      "Cluster 636\n",
      "['living']\n",
      "\n",
      "Cluster 637\n",
      "['then']\n",
      "\n",
      "Cluster 638\n",
      "['told']\n",
      "\n",
      "Cluster 639\n",
      "['tom']\n",
      "\n",
      "Cluster 640\n",
      "['sandy']\n",
      "\n",
      "Cluster 641\n",
      "['been']\n",
      "\n",
      "Cluster 642\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 643\n",
      "['should']\n",
      "\n",
      "Cluster 644\n",
      "['find']\n",
      "\n",
      "Cluster 645\n",
      "['refer']\n",
      "\n",
      "Cluster 646\n",
      "['history']\n",
      "\n",
      "Cluster 647\n",
      "['smiled']\n",
      "\n",
      "Cluster 648\n",
      "['guiltily']\n",
      "\n",
      "Cluster 649\n",
      "['added']\n",
      "\n",
      "Cluster 650\n",
      "['but']\n",
      "\n",
      "Cluster 651\n",
      "['must']\n",
      "\n",
      "Cluster 652\n",
      "['than']\n",
      "\n",
      "Cluster 653\n",
      "['concerned']\n",
      "\n",
      "Cluster 654\n",
      "[' ', ' ']\n",
      "\n",
      "Cluster 655\n",
      "['yes']\n",
      "\n",
      "Cluster 656\n",
      "['wet']\n",
      "\n",
      "Cluster 657\n",
      "['an']\n",
      "\n",
      "Cluster 658\n",
      "['sticky']\n",
      "\n",
      "Cluster 659\n",
      "['right', 'right']\n",
      "\n",
      "Cluster 660\n",
      "['agreed']\n",
      "\n",
      "Cluster 661\n",
      "['sailor']\n",
      "\n",
      "Cluster 662\n",
      "['helped']\n",
      "\n",
      "Cluster 663\n",
      "['us']\n",
      "\n",
      "Cluster 664\n",
      "['got']\n",
      "\n",
      "Cluster 665\n",
      "['through']\n",
      "\n",
      "Cluster 666\n",
      "[' ']\n",
      "\n",
      "Cluster 667\n",
      "['kirkland']\n",
      "\n",
      "Cluster 668\n",
      "[' ']\n",
      "\n",
      "Cluster 669\n",
      "['ghastly']\n",
      "\n",
      "Cluster 670\n",
      "[' ', 'bleeding']\n",
      "\n",
      "Cluster 671\n",
      "['woollen']\n",
      "\n",
      "Cluster 672\n",
      "['torn']\n",
      "\n",
      "Cluster 673\n",
      "['blue']\n",
      "\n",
      "Cluster 674\n",
      "['eyes']\n",
      "\n",
      "Cluster 675\n",
      "['wide']\n",
      "\n",
      "Cluster 676\n",
      "['open']\n",
      "\n",
      "Cluster 677\n",
      "['terror']\n",
      "\n",
      "Cluster 678\n",
      "['clinging']\n",
      "\n",
      "Cluster 679\n",
      "[' ']\n",
      "\n",
      "Cluster 680\n",
      "['german']\n",
      "\n",
      "Cluster 681\n",
      "['lighter']\n",
      "\n",
      "Cluster 682\n",
      "['termed']\n",
      "\n",
      "Cluster 683\n",
      "['rhein']\n",
      "\n",
      "Cluster 684\n",
      "['promised', 'promise']\n",
      "\n",
      "Cluster 685\n",
      "['do']\n",
      "\n",
      "Cluster 686\n",
      "['toward']\n",
      "\n",
      "Cluster 687\n",
      "['catherine']\n",
      "\n",
      "Cluster 688\n",
      "['sydney', 'sydney']\n",
      "\n",
      "Cluster 689\n",
      "['interview']\n",
      "\n",
      "Cluster 690\n",
      "['how']\n",
      "\n",
      "Cluster 691\n",
      "['now']\n",
      "\n",
      "Cluster 692\n",
      "['don']\n",
      "\n",
      "Cluster 693\n",
      "[' ']\n",
      "\n",
      "Cluster 694\n",
      "['eighteen']\n",
      "\n",
      "Cluster 695\n",
      "['ninety']\n",
      "\n",
      "Cluster 696\n",
      "['eight']\n",
      "\n",
      "Cluster 697\n",
      "['nineteen']\n",
      "\n",
      "Cluster 698\n",
      "['o']\n",
      "\n",
      "Cluster 699\n",
      "['our', 'our', 'our']\n",
      "\n",
      "Cluster 700\n",
      "['bench']\n",
      "\n",
      "Cluster 701\n",
      "['what']\n",
      "\n",
      "Cluster 702\n",
      "['his']\n",
      "\n",
      "Cluster 703\n",
      "['body']\n",
      "\n",
      "Cluster 704\n",
      "['was']\n",
      "\n",
      "Cluster 705\n",
      "['gwynplaine', 'gwynplaine']\n",
      "\n",
      "Cluster 706\n",
      "['ate']\n",
      "\n",
      "Cluster 707\n",
      "['in']\n",
      "\n",
      "Cluster 708\n",
      "['position']\n",
      "\n",
      "Cluster 709\n",
      "[' ']\n",
      "\n",
      "Cluster 710\n",
      "['promises']\n",
      "\n",
      "Cluster 711\n",
      "[' ']\n",
      "\n",
      "Cluster 712\n",
      "['lodged']\n",
      "\n",
      "Cluster 713\n",
      "['branches']\n",
      "\n",
      "Cluster 714\n",
      "['pinyon']\n",
      "\n",
      "Cluster 715\n",
      "['is', 'is']\n",
      "\n",
      "Cluster 716\n",
      "['but']\n",
      "\n",
      "Cluster 717\n",
      "[\"doesn't\"]\n",
      "\n",
      "Cluster 718\n",
      "['flesh']\n",
      "\n",
      "Cluster 719\n",
      "['raimented']\n",
      "\n",
      "Cluster 720\n",
      "[' ']\n",
      "\n",
      "Cluster 721\n",
      "['killed']\n",
      "\n",
      "Cluster 722\n",
      "['and']\n",
      "\n",
      "Cluster 723\n",
      "['buried']\n",
      "\n",
      "Cluster 724\n",
      "['arose']\n",
      "\n",
      "Cluster 725\n",
      "['life']\n",
      "\n",
      "Cluster 726\n",
      "['victory']\n",
      "\n",
      "Cluster 727\n",
      "['heaven']\n",
      "\n",
      "Cluster 728\n",
      "['of', 'of']\n",
      "\n",
      "Cluster 729\n",
      "['us']\n",
      "\n",
      "Cluster 730\n",
      "['glorious']\n",
      "\n",
      "Cluster 731\n",
      "['like']\n",
      "\n",
      "Cluster 732\n",
      "['him']\n",
      "\n",
      "Cluster 733\n",
      "['hearts']\n",
      "\n",
      "Cluster 734\n",
      "['his']\n",
      "\n",
      "Cluster 735\n",
      "['they']\n",
      "\n",
      "Cluster 736\n",
      "['die']\n",
      "\n",
      "Cluster 737\n",
      "['love']\n",
      "\n",
      "Cluster 738\n",
      "['reason']\n",
      "\n",
      "Cluster 739\n",
      "['hypocrites']\n",
      "\n",
      "Cluster 740\n",
      "[' ']\n",
      "\n",
      "Cluster 741\n",
      "['sell']\n",
      "\n",
      "Cluster 742\n",
      "['hell']\n",
      "\n",
      "Cluster 743\n",
      "[' ']\n",
      "\n",
      "Cluster 744\n",
      "['saint']\n",
      "\n",
      "Cluster 745\n",
      "['condemns']\n",
      "\n",
      "Cluster 746\n",
      "['does']\n",
      "\n",
      "Cluster 747\n",
      "['law']\n",
      "\n",
      "Cluster 748\n",
      "['judge']\n",
      "\n",
      "Cluster 749\n",
      "['and']\n",
      "\n",
      "Cluster 750\n",
      "['weapon']\n",
      "\n",
      "Cluster 751\n",
      "['gradually']\n",
      "\n",
      "Cluster 752\n",
      "['relief']\n",
      "\n",
      "Cluster 753\n",
      "['did']\n",
      "\n",
      "Cluster 754\n",
      "['suppose', 'suppose']\n",
      "\n",
      "Cluster 755\n",
      "['like']\n",
      "\n",
      "Cluster 756\n",
      "['one']\n",
      "\n",
      "Cluster 757\n",
      "['handsome']\n",
      "\n",
      "Cluster 758\n",
      "['residences']\n",
      "\n",
      "Cluster 759\n",
      "[' ']\n",
      "\n",
      "Cluster 760\n",
      "['evidently']\n",
      "\n",
      "Cluster 761\n",
      "['surprised']\n",
      "\n",
      "Cluster 762\n",
      "['then']\n",
      "\n",
      "Cluster 763\n",
      "['forward']\n",
      "\n",
      "Cluster 764\n",
      "['said']\n",
      "\n",
      "Cluster 765\n",
      "['john']\n",
      "\n",
      "Cluster 766\n",
      "['sight']\n",
      "\n",
      "Cluster 767\n",
      "['god']\n",
      "\n",
      "Cluster 768\n",
      "['i']\n",
      "\n",
      "Cluster 769\n",
      "['have', 'have', 'have']\n",
      "\n",
      "Cluster 770\n",
      "['right']\n",
      "\n",
      "Cluster 771\n",
      "['to']\n",
      "\n",
      "Cluster 772\n",
      "['there']\n",
      "\n",
      "Cluster 773\n",
      "['either']\n",
      "\n",
      "Cluster 774\n",
      "['when']\n",
      "\n",
      "Cluster 775\n",
      "['touched']\n",
      "\n",
      "Cluster 776\n",
      "['shoulder']\n",
      "\n",
      "Cluster 777\n",
      "['looked']\n",
      "\n",
      "Cluster 778\n",
      "['searchingly']\n",
      "\n",
      "Cluster 779\n",
      "['down']\n",
      "\n",
      "Cluster 780\n",
      "['face', 'face']\n",
      "\n",
      "Cluster 781\n",
      "['several']\n",
      "\n",
      "Cluster 782\n",
      "['glory']\n",
      "\n",
      "Cluster 783\n",
      "['bridge']\n",
      "\n",
      "Cluster 784\n",
      "['bond']\n",
      "\n",
      "Cluster 785\n",
      "['between']\n",
      "\n",
      "Cluster 786\n",
      "['usually']\n",
      "\n",
      "Cluster 787\n",
      "['formed']\n",
      "\n",
      "Cluster 788\n",
      "['youth']\n",
      "\n",
      "Cluster 789\n",
      "['randal']\n",
      "\n",
      "Cluster 790\n",
      "['where']\n",
      "\n",
      "Cluster 791\n",
      "['entered']\n",
      "\n",
      "Cluster 792\n",
      "[' ']\n",
      "\n",
      "Cluster 793\n",
      "['had']\n",
      "\n",
      "Cluster 794\n",
      "['training']\n",
      "\n",
      "Cluster 795\n",
      "['tricks']\n",
      "\n",
      "Cluster 796\n",
      "['well', 'well']\n",
      "\n",
      "Cluster 797\n",
      "[' ']\n",
      "\n",
      "Cluster 798\n",
      "[' ']\n",
      "\n",
      "Cluster 799\n",
      "['at']\n",
      "\n",
      "Cluster 800\n",
      "['leaves']\n",
      "\n",
      "Cluster 801\n",
      "['are']\n",
      "\n",
      "Cluster 802\n",
      "['used']\n",
      "\n",
      "Cluster 803\n",
      "[' ']\n",
      "\n",
      "Cluster 804\n",
      "['an']\n",
      "\n",
      "Cluster 805\n",
      "['aromatic']\n",
      "\n",
      "Cluster 806\n",
      "['it']\n",
      "\n",
      "Cluster 807\n",
      "['attention']\n",
      "\n",
      "Cluster 808\n",
      "[' ']\n",
      "\n",
      "Cluster 809\n",
      "['dramatize']\n",
      "\n",
      "Cluster 810\n",
      "['then']\n",
      "\n",
      "Cluster 811\n",
      "['regiment']\n",
      "\n",
      "Cluster 812\n",
      "['to']\n",
      "\n",
      "Cluster 813\n",
      "['carrie']\n",
      "\n",
      "Cluster 814\n",
      "['sound']\n",
      "\n",
      "Cluster 815\n",
      "['bells']\n",
      "\n",
      "Cluster 816\n",
      "['horse']\n",
      "\n",
      "Cluster 817\n",
      "['cars']\n",
      "\n",
      "Cluster 818\n",
      "['in']\n",
      "\n",
      "Cluster 819\n",
      "['out']\n",
      "\n",
      "Cluster 820\n",
      "['hearing']\n",
      "\n",
      "Cluster 821\n",
      "['as']\n",
      "\n",
      "Cluster 822\n",
      "['novel']\n",
      "\n",
      "Cluster 823\n",
      "['brion']\n",
      "\n",
      "Cluster 824\n",
      "['close']\n",
      "\n",
      "Cluster 825\n",
      "['to']\n",
      "\n",
      "Cluster 826\n",
      "['panic']\n",
      "\n",
      "Cluster 827\n",
      "['when']\n",
      "\n",
      "Cluster 828\n",
      "['legal']\n",
      "\n",
      "Cluster 829\n",
      "['sentence']\n",
      "\n",
      "Cluster 830\n",
      "['royal']\n",
      "\n",
      "Cluster 831\n",
      "['mandate']\n",
      "\n",
      "Cluster 832\n",
      "[' ']\n",
      "\n",
      "Cluster 833\n",
      "['dawn', 'dawn']\n",
      "\n",
      "Cluster 834\n",
      "['seditious']\n",
      "\n",
      "Cluster 835\n",
      "['multitude']\n",
      "\n",
      "Cluster 836\n",
      "['attack']\n",
      "\n",
      "Cluster 837\n",
      "['synagogues']\n",
      "\n",
      "Cluster 838\n",
      "['stairs']\n",
      "\n",
      "Cluster 839\n",
      "['showed']\n",
      "\n",
      "Cluster 840\n",
      "['mary']\n",
      "\n",
      "Cluster 841\n",
      "['need']\n",
      "\n",
      "Cluster 842\n",
      "['fear']\n",
      "\n",
      "Cluster 843\n",
      "['going']\n",
      "\n",
      "Cluster 844\n",
      "['home']\n",
      "\n",
      "Cluster 845\n",
      "['through']\n",
      "\n",
      "Cluster 846\n",
      "['deserted']\n",
      "\n",
      "Cluster 847\n",
      "['streets']\n",
      "\n",
      "Cluster 848\n",
      "['try']\n",
      "\n",
      "Cluster 849\n",
      "['and']\n",
      "\n",
      "Cluster 850\n",
      "['get']\n",
      "\n",
      "Cluster 851\n",
      "['sleep']\n",
      "\n",
      "Cluster 852\n",
      "['work']\n",
      "\n",
      "Cluster 853\n",
      "['hour']\n",
      "\n",
      "Cluster 854\n",
      "['sweet', 'sweet']\n",
      "\n",
      "Cluster 855\n",
      "['cultivated']\n",
      "\n",
      "Cluster 856\n",
      "['purposes']\n",
      "\n",
      "Cluster 857\n",
      "['medicine']\n",
      "\n",
      "Cluster 858\n",
      "['perfumery']\n",
      "\n",
      "Cluster 859\n",
      "['grateful']\n",
      "\n",
      "Cluster 860\n",
      "['taste']\n",
      "\n",
      "Cluster 861\n",
      "['smelling']\n",
      "\n",
      "Cluster 862\n",
      "['aroma']\n",
      "\n",
      "Cluster 863\n",
      "['derived']\n",
      "\n",
      "Cluster 864\n",
      "['them']\n",
      "\n",
      "Cluster 865\n",
      "['a']\n",
      "\n",
      "Cluster 866\n",
      "[' ']\n",
      "\n",
      "Cluster 867\n",
      "['great']\n",
      "\n",
      "Cluster 868\n",
      "['measure']\n",
      "\n",
      "Cluster 869\n",
      "['exhilarating']\n",
      "\n",
      "Cluster 870\n",
      "['fragrance']\n",
      "\n",
      "Cluster 871\n",
      "['meads']\n",
      "\n",
      "Cluster 872\n",
      "['not']\n",
      "\n",
      "Cluster 873\n",
      "['me']\n",
      "\n",
      "Cluster 874\n",
      "['illustration']\n",
      "\n",
      "Cluster 875\n",
      "[' ']\n",
      "\n",
      "Cluster 876\n",
      "['ginger']\n",
      "\n",
      "Cluster 877\n",
      "[' ']\n",
      "\n",
      "Cluster 878\n",
      "['giving', 'giving']\n",
      "\n",
      "Cluster 879\n",
      "['mary']\n",
      "\n",
      "Cluster 880\n",
      "['ann']\n",
      "\n",
      "Cluster 881\n",
      "['you']\n",
      "\n",
      "Cluster 882\n",
      "['whiting']\n",
      "\n",
      "Cluster 883\n",
      "['her']\n",
      "\n",
      "Cluster 884\n",
      "[' ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters_dtw = cluster(dist_mat_dtw, 0.25)\n",
    "clusters = []\n",
    "for i, clust in enumerate(clusters_dtw):\n",
    "    new_cluster = Cluster(id=i)\n",
    "    for w in range(len(clust)):\n",
    "        filename_parts = filenames[clust[w]].split(\"_\")\n",
    "        filename = filename_parts[0]\n",
    "        word_index = int(filename_parts[1])                     \n",
    "        new_cluster.add_word_unit(w, word_index, filename)\n",
    "    clusters.append(new_cluster)\n",
    "\n",
    "for c in clusters:\n",
    "    for word_unit in c.word_dict:\n",
    "        word = true_words_dict[word_unit.file][word_unit.index]\n",
    "        c.add_true_word(word)\n",
    "    \n",
    "    if len(c.word_dict) > 0:  \n",
    "        print(f\"Cluster {c.id}\")                \n",
    "        print(c.true_word_dict)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
